# üìö Exemples d'Int√©gration avec MCP

Ce document pr√©sente des exemples concrets d'int√©gration de Roo avec d'autres services via le protocole MCP (Model Context Protocol). Chaque exemple inclut le code complet, des explications d√©taill√©es et des cas d'usage pratiques.

## Table des mati√®res

1. [Int√©gration avec GitHub](#1-int√©gration-avec-github)
2. [Automatisation syst√®me avec win-cli](#2-automatisation-syst√®me-avec-win-cli)
3. [Recherche et synth√®se avec SearXNG et JinaNavigator](#3-recherche-et-synth√®se-avec-searxng-et-jinavigator)
4. [Analyse de donn√©es avec Jupyter](#4-analyse-de-donn√©es-avec-jupyter)
5. [Traitement de fichiers avec QuickFiles](#5-traitement-de-fichiers-avec-quickfiles)
6. [Int√©gration multi-services](#6-int√©gration-multi-services)

---

## 1. Int√©gration avec GitHub

### Cas d'usage: Gestion automatis√©e de projet GitHub

Cet exemple montre comment utiliser Roo pour automatiser la gestion d'un projet GitHub, incluant la cr√©ation d'issues, la gestion des pull requests et l'analyse de code.

### Configuration du serveur MCP

```bash
# Installation du serveur MCP GitHub (externe)
# Depuis la racine du d√©p√¥t principal
cd mcps/external/github
npx -y @modelcontextprotocol/server-github

# Configuration avec un token GitHub (√† faire une seule fois)
export GITHUB_TOKEN=ghp_votre_token_personnel
```

### Exemple: Cr√©ation d'un rapport de projet

```javascript
// Exemple de workflow d'int√©gration avec GitHub

// 1. R√©cup√©ration des issues ouvertes
const openIssues = await use_mcp_tool({
  server_name: "github",
  tool_name: "list_issues",
  arguments: {
    owner: "votre-organisation",
    repo: "votre-projet",
    state: "open"
  }
});

// 2. Analyse des pull requests
const pullRequests = await use_mcp_tool({
  server_name: "github",
  tool_name: "list_pull_requests",
  arguments: {
    owner: "votre-organisation",
    repo: "votre-projet",
    state: "open"
  }
});

// 3. R√©cup√©ration des derniers commits
const recentCommits = await use_mcp_tool({
  server_name: "github",
  tool_name: "list_commits",
  arguments: {
    owner: "votre-organisation",
    repo: "votre-projet",
    perPage: 10
  }
});

// 4. G√©n√©ration d'un rapport de statut
const statusReport = generateProjectStatusReport(openIssues, pullRequests, recentCommits);

// 5. Cr√©ation d'une issue avec le rapport
await use_mcp_tool({
  server_name: "github",
  tool_name: "create_issue",
  arguments: {
    owner: "votre-organisation",
    repo: "votre-projet",
    title: `Rapport de statut du projet - ${new Date().toISOString().split('T')[0]}`,
    body: statusReport,
    labels: ["rapport", "automatique"]
  }
});
```

### Fonctionnalit√©s avanc√©es

- **Analyse de code automatis√©e**:
  ```javascript
  // Recherche de patterns sp√©cifiques dans le code
  const codeSearchResults = await use_mcp_tool({
    server_name: "github",
    tool_name: "search_code",
    arguments: {
      q: "repo:votre-organisation/votre-projet language:javascript TODO"
    }
  });
  
  // G√©n√©ration d'un rapport de TODOs
  const todoReport = analyzeTodos(codeSearchResults);
  ```

- **Gestion automatis√©e des pull requests**:
  ```javascript
  // Revue automatique des PRs
  for (const pr of pullRequests.data) {
    const files = await use_mcp_tool({
      server_name: "github",
      tool_name: "get_pull_request_files",
      arguments: {
        owner: "votre-organisation",
        repo: "votre-projet",
        pull_number: pr.number
      }
    });
    
    const review = await analyzeChanges(files);
    
    await use_mcp_tool({
      server_name: "github",
      tool_name: "create_pull_request_review",
      arguments: {
        owner: "votre-organisation",
        repo: "votre-projet",
        pull_number: pr.number,
        body: review.comments,
        event: review.recommendation
      }
    });
  }
  ```

## 2. Automatisation syst√®me avec win-cli

### Cas d'usage: Maintenance syst√®me automatis√©e

Cet exemple montre comment utiliser Roo pour automatiser des t√¢ches de maintenance syst√®me sur Windows.

### Configuration du serveur MCP

```bash
# Installation du serveur MCP win-cli (externe)
# Depuis la racine du d√©p√¥t principal
cd mcps/external/win-cli
npx -y @simonb97/server-win-cli
```

### Exemple: Nettoyage et analyse syst√®me

```javascript
// Exemple de workflow d'automatisation syst√®me

// 1. V√©rification de l'espace disque
const diskSpace = await use_mcp_tool({
  server_name: "win-cli",
  tool_name: "execute_command",
  arguments: {
    shell: "powershell",
    command: "Get-PSDrive C | Select-Object Used,Free"
  }
});

// 2. Identification des fichiers volumineux
const largeFiles = await use_mcp_tool({
  server_name: "win-cli",
  tool_name: "execute_command",
  arguments: {
    shell: "powershell",
    command: "Get-ChildItem -Path C:\\ -Recurse -File | Where-Object { $_.Length -gt 100MB } | Sort-Object Length -Descending | Select-Object FullName, @{Name='SizeGB';Expression={$_.Length / 1GB}}"
  }
});

// 3. Nettoyage des fichiers temporaires
const cleanupTemp = await use_mcp_tool({
  server_name: "win-cli",
  tool_name: "execute_command",
  arguments: {
    shell: "powershell",
    command: "Remove-Item -Path $env:TEMP\\* -Recurse -Force -ErrorAction SilentlyContinue"
  }
});

// 4. V√©rification des mises √† jour Windows
const windowsUpdates = await use_mcp_tool({
  server_name: "win-cli",
  tool_name: "execute_command",
  arguments: {
    shell: "powershell",
    command: "Get-WindowsUpdate"
  }
});

// 5. G√©n√©ration d'un rapport de maintenance
const maintenanceReport = generateMaintenanceReport(diskSpace, largeFiles, cleanupTemp, windowsUpdates);
```

### Fonctionnalit√©s avanc√©es

- **Surveillance des performances**:
  ```javascript
  // Collecte de m√©triques de performance
  const performanceMetrics = await use_mcp_tool({
    server_name: "win-cli",
    tool_name: "execute_command",
    arguments: {
      shell: "powershell",
      command: `
        $cpu = (Get-Counter '\\Processor(_Total)\\% Processor Time').CounterSamples.CookedValue
        $memory = (Get-Counter '\\Memory\\Available MBytes').CounterSamples.CookedValue
        $disk = (Get-Counter '\\PhysicalDisk(_Total)\\% Disk Time').CounterSamples.CookedValue
        $network = (Get-Counter '\\Network Interface(*)\\Bytes Total/sec').CounterSamples | Where-Object {$_.InstanceName -notlike '*isatap*'} | Measure-Object -Property CookedValue -Sum
        
        [PSCustomObject]@{
            CPU = $cpu
            MemoryAvailableMB = $memory
            DiskUsage = $disk
            NetworkBytesPerSec = $network.Sum
        } | ConvertTo-Json
      `
    }
  });
  ```

- **Gestion des services**:
  ```javascript
  // V√©rification et red√©marrage des services probl√©matiques
  const services = await use_mcp_tool({
    server_name: "win-cli",
    tool_name: "execute_command",
    arguments: {
      shell: "powershell",
      command: "Get-Service | Where-Object {$_.Status -eq 'Stopped' -and $_.StartType -eq 'Automatic'}"
    }
  });
  
  for (const service of parseServices(services)) {
    await use_mcp_tool({
      server_name: "win-cli",
      tool_name: "execute_command",
      arguments: {
        shell: "powershell",
        command: `Start-Service -Name "${service.Name}" -ErrorAction SilentlyContinue`
      }
    });
  }
  ```

## 3. Recherche et synth√®se avec SearXNG et JinaNavigator

### Cas d'usage: Veille technologique automatis√©e

Cet exemple montre comment utiliser Roo pour effectuer une veille technologique automatis√©e en combinant SearXNG pour la recherche et JinaNavigator pour l'extraction de contenu.

### Configuration des serveurs MCP

```bash
# Installation du serveur MCP SearXNG (externe)
# Depuis la racine du d√©p√¥t principal
cd mcps/external/searxng
node ./dist/index.js

# Installation du serveur MCP JinaNavigator (interne)
# Depuis la racine du d√©p√¥t principal
cd mcps/internal/jinavigator-server
node ./dist/index.js
```

### Exemple: Veille sur une technologie √©mergente

```javascript
// Exemple de workflow de veille technologique

// 1. Recherche d'informations r√©centes
const searchResults = await use_mcp_tool({
  server_name: "searxng",
  tool_name: "searxng_web_search",
  arguments: {
    query: "\"edge computing\" \"nouvelles applications\" site:techcrunch.com OR site:zdnet.fr",
    time_range: "month",
    language: "fr"
  }
});

// 2. Extraction et conversion des articles pertinents
const articles = [];
for (const result of searchResults.results.slice(0, 5)) {
  const article = await use_mcp_tool({
    server_name: "jinavigator",
    tool_name: "convert_web_to_markdown",
    arguments: {
      url: result.url
    }
  });
  
  articles.push({
    title: result.title,
    url: result.url,
    content: article.markdown
  });
}

// 3. Extraction des structures des articles
const outlines = await use_mcp_tool({
  server_name: "jinavigator",
  tool_name: "extract_markdown_outline",
  arguments: {
    urls: articles.map(a => ({ url: a.url })),
    max_depth: 2
  }
});

// 4. G√©n√©ration d'une synth√®se
const techReport = generateTechnologyReport(articles, outlines);
```

### Fonctionnalit√©s avanc√©es

- **Analyse de sentiment et tendances**:
  ```javascript
  // Analyse des tendances et du sentiment
  function analyzeTrends(articles) {
    // Extraction des termes fr√©quents
    const terms = extractFrequentTerms(articles);
    
    // Analyse du sentiment par sujet
    const sentiments = analyzeTopicSentiment(articles, terms);
    
    // Identification des tendances √©mergentes
    const emergingTrends = identifyEmergingTrends(terms, sentiments);
    
    return {
      topTerms: terms.slice(0, 10),
      sentimentAnalysis: sentiments,
      emergingTrends: emergingTrends
    };
  }
  ```

- **Suivi temporel des √©volutions**:
  ```javascript
  // Comparaison avec les donn√©es historiques
  async function compareWithHistoricalData(currentReport) {
    // R√©cup√©ration des rapports pr√©c√©dents
    const previousReports = await loadPreviousReports();
    
    // Analyse des √©volutions
    const evolution = {
      newTopics: findNewTopics(currentReport, previousReports),
      growingTopics: findGrowingTopics(currentReport, previousReports),
      decliningTopics: findDecliningTopics(currentReport, previousReports)
    };
    
    return evolution;
  }
  ```

## 4. Analyse de donn√©es avec Jupyter

### Cas d'usage: Analyse automatis√©e de donn√©es

Cet exemple montre comment utiliser Roo pour automatiser l'analyse de donn√©es avec Jupyter.

### Configuration du serveur MCP

```bash
# Installation du serveur MCP Jupyter (interne)
# Depuis la racine du d√©p√¥t principal
cd mcps/internal/jupyter-mcp-server
node ./dist/index.js
```

### Exemple: Analyse de donn√©es de ventes

```javascript
// Exemple de workflow d'analyse de donn√©es

// 1. Cr√©ation d'un nouveau notebook
const notebook = await use_mcp_tool({
  server_name: "jupyter",
  tool_name: "create_notebook",
  arguments: {
    path: "./analyse_ventes.ipynb",
    kernel: "python3"
  }
});

// 2. D√©marrage d'un kernel
const kernel = await use_mcp_tool({
  server_name: "jupyter",
  tool_name: "start_kernel",
  arguments: {
    kernel_name: "python3"
  }
});

// 3. Ajout des cellules d'importation et chargement de donn√©es
await use_mcp_tool({
  server_name: "jupyter",
  tool_name: "add_cell",
  arguments: {
    path: "./analyse_ventes.ipynb",
    cell_type: "code",
    source: `
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from datetime import datetime

# Configuration
plt.style.use('ggplot')
sns.set(style="whitegrid")
%matplotlib inline
    `
  }
});

await use_mcp_tool({
  server_name: "jupyter",
  tool_name: "add_cell",
  arguments: {
    path: "./analyse_ventes.ipynb",
    cell_type: "code",
    source: `
# Chargement des donn√©es
sales_data = pd.read_csv('ventes_2025.csv')

# Affichage des premi√®res lignes
sales_data.head()
    `
  }
});

// 4. Ajout de cellules d'analyse
await use_mcp_tool({
  server_name: "jupyter",
  tool_name: "add_cell",
  arguments: {
    path: "./analyse_ventes.ipynb",
    cell_type: "code",
    source: `
# Analyse temporelle
sales_data['date'] = pd.to_datetime(sales_data['date'])
sales_data['month'] = sales_data['date'].dt.month
sales_data['day_of_week'] = sales_data['date'].dt.dayofweek

# Ventes mensuelles
monthly_sales = sales_data.groupby('month')['amount'].sum().reset_index()

plt.figure(figsize=(12, 6))
sns.barplot(x='month', y='amount', data=monthly_sales)
plt.title('Ventes mensuelles')
plt.xlabel('Mois')
plt.ylabel('Montant total des ventes')
plt.xticks(range(12), ['Jan', 'F√©v', 'Mar', 'Avr', 'Mai', 'Juin', 'Juil', 'Ao√ªt', 'Sep', 'Oct', 'Nov', 'D√©c'])
plt.show()
    `
  }
});

// 5. Ex√©cution du notebook
await use_mcp_tool({
  server_name: "jupyter",
  tool_name: "execute_notebook",
  arguments: {
    path: "./analyse_ventes.ipynb",
    kernel_id: kernel.id
  }
});

// 6. Arr√™t du kernel
await use_mcp_tool({
  server_name: "jupyter",
  tool_name: "stop_kernel",
  arguments: {
    kernel_id: kernel.id
  }
});
```

### Fonctionnalit√©s avanc√©es

- **Analyse pr√©dictive**:
  ```javascript
  // Ajout d'une cellule pour l'analyse pr√©dictive
  await use_mcp_tool({
    server_name: "jupyter",
    tool_name: "add_cell",
    arguments: {
      path: "./analyse_ventes.ipynb",
      cell_type: "code",
      source: `
  # Pr√©paration des donn√©es pour la pr√©diction
  from sklearn.model_selection import train_test_split
  from sklearn.ensemble import RandomForestRegressor
  from sklearn.metrics import mean_absolute_error, r2_score
  
  # Cr√©ation de features
  features = sales_data[['month', 'day_of_week', 'product_category', 'store_id']]
  features = pd.get_dummies(features, columns=['product_category', 'store_id'])
  target = sales_data['amount']
  
  # Split des donn√©es
  X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)
  
  # Entra√Ænement du mod√®le
  model = RandomForestRegressor(n_estimators=100, random_state=42)
  model.fit(X_train, y_train)
  
  # √âvaluation
  predictions = model.predict(X_test)
  mae = mean_absolute_error(y_test, predictions)
  r2 = r2_score(y_test, predictions)
  
  print(f"MAE: {mae:.2f}")
  print(f"R¬≤: {r2:.2f}")
  
  # Importance des features
  feature_importance = pd.DataFrame({
      'feature': features.columns,
      'importance': model.feature_importances_
  }).sort_values('importance', ascending=False)
  
  plt.figure(figsize=(10, 6))
  sns.barplot(x='importance', y='feature', data=feature_importance.head(10))
  plt.title('Importance des features')
  plt.tight_layout()
  plt.show()
      `
    }
  });
  ```

- **G√©n√©ration de rapport automatique**:
  ```javascript
  // Ajout d'une cellule pour g√©n√©rer un rapport
  await use_mcp_tool({
    server_name: "jupyter",
    tool_name: "add_cell",
    arguments: {
      path: "./analyse_ventes.ipynb",
      cell_type: "code",
      source: `
  # G√©n√©ration d'un rapport automatique
  from IPython.display import Markdown
  
  def generate_sales_report(data, predictions, mae, r2):
      total_sales = data['amount'].sum()
      avg_sales = data['amount'].mean()
      top_category = data.groupby('product_category')['amount'].sum().idxmax()
      top_store = data.groupby('store_id')['amount'].sum().idxmax()
      
      report = f"""
  # Rapport d'analyse des ventes
  
  ## R√©sum√©
  
  - **Total des ventes**: {total_sales:,.2f} ‚Ç¨
  - **Vente moyenne**: {avg_sales:.2f} ‚Ç¨
  - **Cat√©gorie la plus vendue**: {top_category}
  - **Magasin le plus performant**: {top_store}
  
  ## Performance du mod√®le pr√©dictif
  
  - **Erreur absolue moyenne**: {mae:.2f} ‚Ç¨
  - **Coefficient de d√©termination (R¬≤)**: {r2:.2f}
  
  ## Recommandations
  
  1. Concentrer les efforts marketing sur la cat√©gorie {top_category}
  2. Analyser les pratiques du magasin {top_store} pour les r√©pliquer
  3. Optimiser les stocks en fonction des pr√©visions mensuelles
  """
      
      return Markdown(report)
  
  # Affichage du rapport
  generate_sales_report(sales_data, predictions, mae, r2)
      `
    }
  });
  ```

## 5. Traitement de fichiers avec QuickFiles

### Cas d'usage: Traitement par lots de documents

Cet exemple montre comment utiliser Roo pour automatiser le traitement par lots de documents avec QuickFiles.

### Configuration du serveur MCP

```bash
# Installation du serveur MCP QuickFiles (interne)
# Depuis la racine du d√©p√¥t principal
cd mcps/internal/quickfiles-server
node ./build/index.js
```

### Exemple: Analyse et transformation de logs

```javascript
// Exemple de workflow de traitement de fichiers

// 1. Recherche des fichiers de logs
const logFiles = await use_mcp_tool({
  server_name: "quickfiles",
  tool_name: "list_directory_contents",
  arguments: {
    paths: [{
      path: "./logs",
      recursive: true,
      file_pattern: "*.log"
    }]
  }
});

// 2. Lecture du contenu des logs
const logsContent = await use_mcp_tool({
  server_name: "quickfiles",
  tool_name: "read_multiple_files",
  arguments: {
    paths: logFiles.files.map(file => file.path)
  }
});

// 3. Recherche de patterns d'erreurs
const errorPatterns = await use_mcp_tool({
  server_name: "quickfiles",
  tool_name: "search_in_files",
  arguments: {
    paths: logFiles.files.map(file => file.path),
    pattern: "ERROR|CRITICAL|EXCEPTION",
    use_regex: true,
    context_lines: 3
  }
});

// 4. Extraction de la structure des logs
const logStructure = await use_mcp_tool({
  server_name: "quickfiles",
  tool_name: "extract_markdown_structure",
  arguments: {
    paths: logsContent.files.map(file => file.path)
  }
});

// 5. G√©n√©ration d'un rapport d'analyse
const logAnalysisReport = generateLogAnalysisReport(logsContent, errorPatterns, logStructure);

// 6. Transformation des logs (normalisation)
await use_mcp_tool({
  server_name: "quickfiles",
  tool_name: "search_and_replace",
  arguments: {
    files: logsContent.files.map(file => ({
      path: file.path,
      search: "\\[(\\d{4}-\\d{2}-\\d{2} \\d{2}:\\d{2}:\\d{2})\\]",
      replace: "[TIMESTAMP: $1]",
      use_regex: true
    }))
  }
});
```

### Fonctionnalit√©s avanc√©es

- **Agr√©gation et analyse statistique**:
  ```javascript
  // Fonction d'analyse statistique des logs
  function analyzeLogStatistics(logsContent, errorPatterns) {
    // Extraction des timestamps
    const timestamps = extractTimestamps(logsContent);
    
    // Analyse de la distribution temporelle
    const timeDistribution = analyzeTimeDistribution(timestamps);
    
    // Corr√©lation entre erreurs
    const errorCorrelations = findErrorCorrelations(errorPatterns);
    
    // Identification des p√©riodes probl√©matiques
    const problematicPeriods = identifyProblematicPeriods(timestamps, errorPatterns);
    
    return {
      timeDistribution,
      errorCorrelations,
      problematicPeriods
    };
  }
  ```

- **Transformation avanc√©e de fichiers**:
  ```javascript
  // Transformation avanc√©e avec √©dition multiple
  await use_mcp_tool({
    server_name: "quickfiles",
    tool_name: "edit_multiple_files",
    arguments: {
      files: logsContent.files.map(file => ({
        path: file.path,
        diffs: [
          {
            search: "user=(\\w+)",
            replace: "user=[REDACTED]",
            start_line: 1
          },
          {
            search: "password=(\\w+)",
            replace: "password=[REDACTED]",
            start_line: 1
          },
          {
            search: "ip=(\\d+\\.\\d+\\.\\d+\\.\\d+)",
            replace: "ip=[REDACTED]",
            start_line: 1
          }
        ]
      }))
    }
  });
  ```

## 6. Int√©gration multi-services

### Cas d'usage: Pipeline de traitement de donn√©es complet

Cet exemple montre comment combiner plusieurs serveurs MCP pour cr√©er un pipeline de traitement de donn√©es complet.

### Exemple: Collecte, analyse et visualisation de donn√©es

```javascript
// Exemple de workflow multi-services

// 1. Collecte de donn√©es via API (win-cli)
const rawData = await use_mcp_tool({
  server_name: "win-cli",
  tool_name: "execute_command",
  arguments: {
    shell: "powershell",
    command: "Invoke-RestMethod -Uri 'https://api.example.com/data' -Headers @{'Authorization'='Bearer $env:API_KEY'} | ConvertTo-Json -Depth 10"
  }
});

// 2. Sauvegarde des donn√©es brutes (filesystem)
await use_mcp_tool({
  server_name: "filesystem",
  tool_name: "write_file",
  arguments: {
    path: "./data/raw_data.json",
    content: rawData
  }
});

// 3. Enrichissement avec des donn√©es web (searxng + jinavigator)
const searchResults = await use_mcp_tool({
  server_name: "searxng",
  tool_name: "searxng_web_search",
  arguments: {
    query: "latest statistics " + extractKeywords(rawData)
  }
});

const enrichmentData = await use_mcp_tool({
  server_name: "jinavigator",
  tool_name: "convert_web_to_markdown",
  arguments: {
    url: searchResults.results[0].url
  }
});

// 4. Analyse des donn√©es avec Jupyter
// 4.1 Cr√©ation du notebook
const notebook = await use_mcp_tool({
  server_name: "jupyter",
  tool_name: "create_notebook",
  arguments: {
    path: "./analysis/data_analysis.ipynb"
  }
});

// 4.2 D√©marrage du kernel
const kernel = await use_mcp_tool({
  server_name: "jupyter",
  tool_name: "start_kernel",
  arguments: {}
});

// 4.3 Ajout des cellules d'analyse
await use_mcp_tool({
  server_name: "jupyter",
  tool_name: "add_cell",
  arguments: {
    path: "./analysis/data_analysis.ipynb",
    cell_type: "code",
    source: `
import pandas as pd
import json
import matplotlib.pyplot as plt
import seaborn as sns

# Chargement des donn√©es
with open('../data/raw_data.json', 'r') as f:
    data = json.load(f)
    
# Conversion en DataFrame
df = pd.json_normalize(data)

# Analyse exploratoire
print(df.info())
print(df.describe())

# Visualisation
plt.figure(figsize=(12, 8))
sns.heatmap(df.corr(), annot=True, cmap='coolwarm')
plt.title('Matrice de corr√©lation')
plt.tight_layout()
plt.savefig('../reports/correlation_matrix.png')
plt.show()
    `
  }
});

// 4.4 Ex√©cution du notebook
await use_mcp_tool({
  server_name: "jupyter",
  tool_name: "execute_notebook",
  arguments: {
    path: "./analysis/data_analysis.ipynb",
    kernel_id: kernel.id
  }
});

// 5. G√©n√©ration du rapport final (GitHub)
const reportContent = generateFinalReport(rawData, enrichmentData, "./reports/correlation_matrix.png");

await use_mcp_tool({
  server_name: "github",
  tool_name: "create_or_update_file",
  arguments: {
    owner: "votre-organisation",
    repo: "votre-projet",
    path: "reports/data_analysis_report.md",
    content: reportContent,
    message: "Ajout du rapport d'analyse de donn√©es",
    branch: "main"
  }
});
```

### Fonctionnalit√©s avanc√©es

- **Orchestration conditionnelle**:
  ```javascript
  // Fonction d'orchestration conditionnelle
  async function conditionalWorkflow(data) {
    // Analyse pr√©liminaire
    const preliminaryAnalysis = analyzeData(data);
    
    // D√©cision bas√©e sur l'analyse
    if (preliminaryAnalysis.anomalyDetected) {
      // Flux de travail pour les anomalies
      await anomalyWorkflow(data, preliminaryAnalysis);
    } else if (preliminaryAnalysis.qualityIssues) {
      // Flux de travail pour les probl√®mes de qualit√©
      await qualityIssueWorkflow(data, preliminaryAnalysis);
    } else {
      // Flux de travail standard
      await standardWorkflow(data);
    }
  }
  ```

- **Pipeline de traitement parall√®le**:
  ```javascript
  // Fonction de traitement parall√®le
  async function parallelProcessing(data) {
    // Division des donn√©es en segments
    const segments = splitDataIntoSegments(data, 4);
    
    // Traitement parall√®le
    const processingPromises = segments.map(async (segment, index) => {
      // Sauvegarde du segment
      await use_mcp_tool({
        server_name: "filesystem",
        tool_name: "write_file",
        arguments: {
          path: `./data/segment_${index}.json`,
          content: JSON.stringify(segment)
        }
      });
      
      // Traitement du segment
      return processSegment(segment, index);
    });
    
    // Attente de tous les traitements
    const results = await Promise.all(processingPromises);
    
    // Fusion des r√©sultats
    return mergeResults(results);
  }
  ```

---

Ces exemples illustrent comment int√©grer Roo avec diff√©rents services via MCP pour cr√©er des workflows d'automatisation puissants et flexibles. Vous pouvez adapter ces exemples √† vos besoins sp√©cifiques et les combiner pour cr√©er des solutions personnalis√©es.

Pour des conseils sur l'impl√©mentation optimale de ces int√©grations, consultez le guide des [Bonnes pratiques](./bonnes-pratiques.md).