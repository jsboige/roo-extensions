# Analyse Approfondie du Syst√®me Natif de Condensation

**Date**: 2025-01-02  
**Objectif**: Documenter en profondeur le syst√®me de condensation natif de roo-code pour d√©finir la surface de d√©coupage entre Native Provider et Condensation Manager.

---

## 1. Architecture Globale

### 1.1 Flux de Condensation

```
Task.condenseContext() 
    ‚Üì
Task.summarizeConversation()
    ‚Üì
truncateConversationIfNeeded()
    ‚Üì
summarizeConversation()
    ‚Üì
ApiHandler.createMessage()
```

### 1.2 Fichiers Cl√©s

| Fichier | R√¥le | Lignes Importantes |
|---------|------|-------------------|
| [`src/core/condense/index.ts`](../../../src/core/condense/index.ts) | Logique de summarization | 85-212 (summarizeConversation) |
| [`src/core/sliding-window/index.ts`](../../../src/core/sliding-window/index.ts) | Gestion du seuil et d√©clenchement | 91-175 (truncateConversationIfNeeded) |
| [`src/shared/cost.ts`](../../../src/shared/cost.ts) | Calcul des co√ªts | 3-55 |
| [`src/core/task/Task.ts`](../../../src/core/task/Task.ts) | Orchestration | 1010-1025, 2600-2637 |
| [`src/core/webview/ClineProvider.ts`](../../../src/core/webview/ClineProvider.ts) | Configuration globale | 2086-2168 |

---

## 2. Profils de Condensation

### 2.1 Concept de Profils

Le syst√®me utilise **deux niveaux de profils**:

1. **Profils API** (`listApiConfigMeta`): Configurations de providers (Anthropic, OpenAI, etc.)
2. **Profils de Seuil** (`profileThresholds`): Seuils personnalis√©s par profil API

### 2.2 Configuration des Profils

#### Dans `ClineProvider.ts` (lignes 2150-2168)

```typescript
// Configuration globale
condensingApiConfigId?: string        // ID du profil API pour la condensation
customCondensingPrompt?: string       // Prompt personnalis√© (optionnel)
profileThresholds: Record<string, number>  // Seuils par profil API
```

#### Dans `sliding-window/index.ts` (lignes 126-142)

```typescript
// D√©termination du seuil effectif
let effectiveThreshold = autoCondenseContextPercent  // Global par d√©faut
const profileThreshold = profileThresholds[currentProfileId]

if (profileThreshold !== undefined) {
    if (profileThreshold === -1) {
        // -1 = h√©rite du seuil global
        effectiveThreshold = autoCondenseContextPercent
    } else if (profileThreshold >= MIN_CONDENSE_THRESHOLD && 
               profileThreshold <= MAX_CONDENSE_THRESHOLD) {
        // Utilise le seuil personnalis√© du profil
        effectiveThreshold = profileThreshold
    } else {
        // Invalide ‚Üí fallback au global
        console.warn(...)
        effectiveThreshold = autoCondenseContextPercent
    }
}
```

### 2.3 S√©lection du Handler API

#### Dans `condense/index.ts` (lignes 136-159)

```typescript
// S√©lection du handler pour la condensation
const promptToUse = customCondensingPrompt?.trim() 
    ? customCondensingPrompt.trim() 
    : SUMMARY_PROMPT

let handlerToUse = condensingApiHandler || apiHandler  // Priorit√© au handler sp√©cifique

// Validation du handler
if (!handlerToUse || typeof handlerToUse.createMessage !== "function") {
    console.warn("Handler invalide, fallback vers apiHandler principal")
    handlerToUse = apiHandler
    
    if (!handlerToUse || typeof handlerToUse.createMessage !== "function") {
        return { ...response, error: t("common:errors.condense_handler_invalid") }
    }
}
```

### 2.4 Diff√©rences entre Profils

| Aspect | Profil Global (d√©faut) | Profil Personnalis√© |
|--------|----------------------|---------------------|
| **API Handler** | `apiHandler` (courant) | `condensingApiHandler` (optionnel) |
| **Prompt** | `SUMMARY_PROMPT` | `customCondensingPrompt` (optionnel) |
| **Seuil** | `autoCondenseContextPercent` | `profileThresholds[profileId]` |
| **Mod√®le** | Mod√®le actuel | Peut √™tre diff√©rent (ex: GPT-4o-mini pour co√ªt) |
| **Co√ªt** | Calcul√© selon mod√®le actuel | Optimisable avec mod√®le moins cher |

---

## 3. Param√®tres et Seuils Configurables

### 3.1 Constantes Syst√®me

#### `condense/index.ts` (lignes 10-12)

```typescript
export const N_MESSAGES_TO_KEEP = 3           // Nombre de messages r√©cents pr√©serv√©s
export const MIN_CONDENSE_THRESHOLD = 5       // Seuil minimum (5%)
export const MAX_CONDENSE_THRESHOLD = 100     // Seuil maximum (100%)
```

#### `sliding-window/index.ts` (ligne 13)

```typescript
export const TOKEN_BUFFER_PERCENTAGE = 0.1    // 10% de buffer pour s√©curit√©
```

### 3.2 Param√®tres Configurables Globaux

#### Dans `ClineProvider.getState()` (lignes 2086-2168)

| Param√®tre | Type | D√©faut | Description |
|-----------|------|--------|-------------|
| `autoCondenseContext` | `boolean` | `true` | Active/d√©sactive la condensation auto |
| `autoCondenseContextPercent` | `number` | `100` | Seuil global (% de contextWindow) |
| `condensingApiConfigId` | `string?` | `undefined` | ID du profil API pour condensation |
| `customCondensingPrompt` | `string?` | `undefined` | Prompt personnalis√© |
| `profileThresholds` | `Record<string, number>` | `{}` | Seuils personnalis√©s par profil |

### 3.3 Param√®tres Calcul√©s Dynamiquement

#### Dans `sliding-window/index.ts` (lignes 109-123)

```typescript
// Calculs dynamiques
const reservedTokens = maxTokens || ANTHROPIC_DEFAULT_MAX_TOKENS
const lastMessageTokens = await estimateTokenCount(lastMessageContent, apiHandler)
const prevContextTokens = totalTokens + lastMessageTokens
const allowedTokens = contextWindow * (1 - TOKEN_BUFFER_PERCENTAGE) - reservedTokens

// D√©clenchement
const contextPercent = (100 * prevContextTokens) / contextWindow
if (contextPercent >= effectiveThreshold || prevContextTokens > allowedTokens) {
    // Condensation d√©clench√©e
}
```

### 3.4 Validation des Param√®tres

#### Seuil de Profil (lignes 128-142)

```typescript
if (profileThreshold !== undefined) {
    if (profileThreshold === -1) {
        // H√©ritage OK
    } else if (profileThreshold >= MIN_CONDENSE_THRESHOLD && 
               profileThreshold <= MAX_CONDENSE_THRESHOLD) {
        // Valide
    } else {
        // Invalide ‚Üí warning + fallback
        console.warn(`Invalid profile threshold ${profileThreshold}...`)
    }
}
```

---

## 4. Calcul du Co√ªt

### 4.1 Architecture du Calcul

#### Fonction Interne Partag√©e (`cost.ts` lignes 3-16)

```typescript
function calculateApiCostInternal(
    modelInfo: ModelInfo,
    inputTokens: number,
    outputTokens: number,
    cacheCreationInputTokens: number,
    cacheReadInputTokens: number,
): number {
    const cacheWritesCost = ((modelInfo.cacheWritesPrice || 0) / 1_000_000) 
                          * cacheCreationInputTokens
    const cacheReadsCost = ((modelInfo.cacheReadsPrice || 0) / 1_000_000) 
                         * cacheReadInputTokens
    const baseInputCost = ((modelInfo.inputPrice || 0) / 1_000_000) 
                        * inputTokens
    const outputCost = ((modelInfo.outputPrice || 0) / 1_000_000) 
                     * outputTokens
    
    return cacheWritesCost + cacheReadsCost + baseInputCost + outputCost
}
```

### 4.2 Diff√©rence Anthropic vs OpenAI

#### Anthropic (`cost.ts` lignes 20-34)

```typescript
// inputTokens N'INCLUT PAS les tokens cach√©s
export function calculateApiCostAnthropic(
    modelInfo: ModelInfo,
    inputTokens: number,              // Tokens non-cach√©s uniquement
    outputTokens: number,
    cacheCreationInputTokens?: number,
    cacheReadInputTokens?: number,
): number {
    return calculateApiCostInternal(
        modelInfo,
        inputTokens,                   // Utilis√© tel quel
        outputTokens,
        cacheCreationInputTokens || 0,
        cacheReadInputTokens || 0,
    )
}
```

#### OpenAI (`cost.ts` lignes 37-55)

```typescript
// inputTokens INCLUT les tokens cach√©s
export function calculateApiCostOpenAI(
    modelInfo: ModelInfo,
    inputTokens: number,               // Total incluant cache
    outputTokens: number,
    cacheCreationInputTokens?: number,
    cacheReadInputTokens?: number,
): number {
    const cacheCreationInputTokensNum = cacheCreationInputTokens || 0
    const cacheReadInputTokensNum = cacheReadInputTokens || 0
    
    // Soustraction pour isoler les tokens non-cach√©s
    const nonCachedInputTokens = Math.max(
        0, 
        inputTokens - cacheCreationInputTokensNum - cacheReadInputTokensNum
    )

    return calculateApiCostInternal(
        modelInfo,
        nonCachedInputTokens,          // Tokens recalcul√©s
        outputTokens,
        cacheCreationInputTokensNum,
        cacheReadInputTokensNum,
    )
}
```

### 4.3 Formule Compl√®te

```
Co√ªt Total = Co√ªt √âcriture Cache + Co√ªt Lecture Cache + Co√ªt Input Base + Co√ªt Output

O√π:
  Co√ªt √âcriture Cache = (prix_√©criture / 1M) √ó tokens_cr√©ation_cache
  Co√ªt Lecture Cache  = (prix_lecture / 1M) √ó tokens_lecture_cache
  Co√ªt Input Base     = (prix_input / 1M) √ó tokens_input_non_cach√©s
  Co√ªt Output         = (prix_output / 1M) √ó tokens_output
```

### 4.4 Co√ªt de Condensation

#### Calcul dans `condense/index.ts` (lignes 163-175)

```typescript
const stream = handlerToUse.createMessage(promptToUse, requestMessages)

let summary = ""
let cost = 0
let outputTokens = 0

for await (const chunk of stream) {
    if (chunk.type === "text") {
        summary += chunk.text
    } else if (chunk.type === "usage") {
        cost = chunk.totalCost ?? 0        // Co√ªt calcul√© par le handler
        outputTokens = chunk.outputTokens ?? 0
    }
}
```

### 4.5 Impact du Profil sur le Co√ªt

| Sc√©nario | Handler | Mod√®le | Co√ªt Typique |
|----------|---------|--------|--------------|
| **Sans profil personnalis√©** | `apiHandler` | Claude Sonnet 4 | ~$0.015-0.030 |
| **Avec profil optimis√©** | `condensingApiHandler` | GPT-4o-mini | ~$0.001-0.003 |
| **√âconomie potentielle** | - | - | **90%+** |

**Exemple Concret**:
```
Conversation: 50 messages, 20K tokens input
R√©sum√©: ~1K tokens output

Sans optimisation (Claude Sonnet):
  Input:  $3.00/1M √ó 20K = $0.060
  Output: $15.00/1M √ó 1K = $0.015
  Total: $0.075

Avec profil GPT-4o-mini:
  Input:  $0.15/1M √ó 20K = $0.003
  Output: $0.60/1M √ó 1K = $0.0006
  Total: $0.0036

√âconomie: 95.2% ($0.0714)
```

---

## 5. Logique de Condensation

### 5.1 Conditions de D√©clenchement

#### Automatique (`sliding-window/index.ts` lignes 145-166)

```typescript
if (autoCondenseContext) {
    const contextPercent = (100 * prevContextTokens) / contextWindow
    
    // D√©clenchement si:
    // 1. Pourcentage ‚â• seuil effectif OU
    // 2. Tokens absolus > allowedTokens
    if (contextPercent >= effectiveThreshold || prevContextTokens > allowedTokens) {
        const result = await summarizeConversation(
            messages,
            apiHandler,
            systemPrompt,
            taskId,
            prevContextTokens,
            true,                      // automatic trigger
            customCondensingPrompt,
            condensingApiHandler,
        )
        
        if (result.error) {
            error = result.error
            cost = result.cost
            // Fallback vers sliding window
        } else {
            return { ...result, prevContextTokens }
        }
    }
}
```

#### Manuel (`Task.ts` lignes 1010-1025)

```typescript
async condenseContext() {
    const result = await summarizeConversation(
        this.apiConversationHistory,
        this.api,                      // Main API handler (fallback)
        systemPrompt,                  // Default prompt (fallback)
        this.taskId,
        prevContextTokens,
        false,                         // manual trigger
        customCondensingPrompt,        // User's custom prompt
        condensingApiHandler,          // Specific handler for condensing
    )
    // ...
}
```

### 5.2 Validation des Conditions

#### `condense/index.ts` (lignes 107-124)

```typescript
// 1. Minimum de messages
const messagesToSummarize = getMessagesSinceLastSummary(
    messages.slice(0, -N_MESSAGES_TO_KEEP)
)

if (messagesToSummarize.length <= 1) {
    return { ...response, error: t("common:errors.condense_not_enough_messages") }
}

// 2. Pas de r√©sum√© r√©cent dans les N derniers messages
const keepMessages = messages.slice(-N_MESSAGES_TO_KEEP)
const recentSummaryExists = keepMessages.some(msg => msg.isSummary)

if (recentSummaryExists) {
    return { ...response, error: t("common:errors.condensed_recently") }
}
```

### 5.3 Structure du R√©sum√©

#### Messages R√©sultants (lignes 191-192)

```typescript
// Structure finale: [firstMessage, summaryMessage, ...lastNMessages]
const newMessages = [firstMessage, summaryMessage, ...keepMessages]
```

#### Garantie de R√©duction (lignes 206-210)

```typescript
const newContextTokens = outputTokens + (await apiHandler.countTokens(contextBlocks))

if (newContextTokens >= prevContextTokens) {
    return { ...response, cost, error: t("common:errors.condense_context_grew") }
}
```

### 5.4 Fallback Automatique

#### `sliding-window/index.ts` (lignes 168-172)

```typescript
// Si condensation √©choue ou d√©sactiv√©e
if (prevContextTokens > allowedTokens) {
    const truncatedMessages = truncateConversation(messages, 0.5, taskId)
    return { messages: truncatedMessages, prevContextTokens, summary: "", cost, error }
}
```

---

## 6. Surface de D√©coupage

### 6.1 Analyse de Responsabilit√©s

#### Actuellement dans Native Provider

| Responsabilit√© | Fichier | Lignes | Pourquoi Native? |
|---------------|---------|--------|------------------|
| **S√©lection du handler** | `condense/index.ts` | 136-159 | Acc√®s direct aux handlers |
| **Validation du handler** | `condense/index.ts` | 143-158 | Connaissance des interfaces |
| **Appel LLM** | `condense/index.ts` | 161-175 | Streaming natif |
| **Comptage tokens** | `condense/index.ts` | 196-206 | API handler sp√©cifique |
| **Calcul co√ªt** | `cost.ts` | 3-55 | Connaissance des pricing |
| **D√©termination seuil** | `sliding-window/index.ts` | 126-142 | Logique m√©tier simple |
| **D√©clenchement** | `sliding-window/index.ts` | 145-166 | Orchestration native |

#### Candidates pour Manager

| Responsabilit√© | Raison | Priorit√© |
|---------------|--------|----------|
| **Configuration profils** | Logique m√©tier, pas technique | ‚≠ê‚≠ê‚≠ê |
| **Gestion seuils** | Peut √™tre abstraite | ‚≠ê‚≠ê‚≠ê |
| **Strat√©gie de fallback** | D√©cision m√©tier | ‚≠ê‚≠ê |
| **Tracking co√ªts** | Aggr√©gation, analytics | ‚≠ê‚≠ê |
| **Validation contexte** | R√®gles m√©tier | ‚≠ê |

### 6.2 Proposition de D√©coupage

#### üü¢ Reste dans Native Provider

```typescript
// core/condense/NativeCondensationProvider.ts
class NativeCondensationProvider {
    // ‚úÖ Garde la logique technique
    async condense(messages, config): Promise<CondensationResult> {
        const handler = this.selectHandler(config)
        const prompt = this.selectPrompt(config)
        const stream = handler.createMessage(prompt, messages)
        // ... streaming, tokens, cost
    }
    
    private selectHandler(config): ApiHandler {
        // Logique de s√©lection/validation
    }
    
    private async countTokens(content): Promise<number> {
        // Comptage natif
    }
    
    private calculateCost(usage, modelInfo): number {
        // Calcul natif
    }
}
```

#### üîµ Monte dans Manager

```typescript
// core/condense/CondensationManager.ts
class CondensationManager {
    // ‚úÖ G√®re la configuration
    getEffectiveConfig(profileId: string): CondensationConfig {
        const profile = this.profiles[profileId]
        return {
            threshold: profile?.threshold ?? this.globalThreshold,
            apiConfigId: profile?.apiConfigId,
            customPrompt: profile?.customPrompt,
        }
    }
    
    // ‚úÖ D√©cide du d√©clenchement
    shouldCondense(tokens, contextWindow, config): boolean {
        const percent = (100 * tokens) / contextWindow
        return percent >= config.threshold
    }
    
    // ‚úÖ Orchestration strat√©gie
    async condenseIfNeeded(messages, config): Promise<Result> {
        if (!this.shouldCondense(...)) {
            return { messages, didCondense: false }
        }
        
        try {
            return await this.provider.condense(messages, config)
        } catch (error) {
            // Fallback strategy
            return this.handleFallback(messages, error)
        }
    }
    
    // ‚úÖ Gestion profils
    setProfileThreshold(profileId: string, threshold: number) {
        this.profiles[profileId] = { ...this.profiles[profileId], threshold }
    }
}
```

### 6.3 Interface Provider

```typescript
// core/condense/interfaces.ts
export interface CondensationProvider {
    /**
     * Condense une conversation en utilisant un LLM
     */
    condense(
        messages: ApiMessage[],
        config: CondensationConfig,
    ): Promise<CondensationResult>
    
    /**
     * Compte les tokens d'un contenu
     */
    countTokens(content: ContentBlock[]): Promise<number>
    
    /**
     * Calcule le co√ªt d'une op√©ration
     */
    calculateCost(usage: Usage, modelInfo: ModelInfo): number
}

export interface CondensationConfig {
    apiHandler: ApiHandler          // Handler principal (fallback)
    condensingApiHandler?: ApiHandler  // Handler sp√©cifique
    systemPrompt: string            // Prompt syst√®me (fallback)
    customPrompt?: string           // Prompt personnalis√©
    prevContextTokens: number       // Contexte actuel
    taskId: string                  // Pour t√©l√©m√©trie
    isAutomatic: boolean            // Auto vs manuel
}

export interface CondensationResult {
    messages: ApiMessage[]          // Messages condens√©s
    summary: string                 // Texte du r√©sum√©
    cost: number                    // Co√ªt de l'op√©ration
    newContextTokens?: number       // Nouveaux tokens
    error?: string                  // Erreur √©ventuelle
}
```

### 6.4 Flux Propos√©

```
Task.condenseContext()
    ‚Üì
[MANAGER] CondensationManager.condenseIfNeeded()
    ‚îú‚îÄ shouldCondense() ‚Üí bool
    ‚îú‚îÄ getEffectiveConfig() ‚Üí config
    ‚îî‚îÄ Si oui:
        ‚Üì
[PROVIDER] NativeCondensationProvider.condense()
    ‚îú‚îÄ selectHandler()
    ‚îú‚îÄ selectPrompt()
    ‚îú‚îÄ createMessage() (streaming)
    ‚îú‚îÄ countTokens()
    ‚îî‚îÄ calculateCost()
        ‚Üì
[MANAGER] handleResult() / handleFallback()
    ‚Üì
Task (continue)
```

---

## 7. Recommandations d'Architecture

### 7.1 Principes de D√©coupage

1. **üî¥ Native = Technique**: Tout ce qui touche directement aux APIs, handlers, streaming
2. **üîµ Manager = M√©tier**: Configuration, d√©cisions, orchestration, fallback
3. **üü¢ Interface = Contrat**: Types partag√©s, pas de logique

### 7.2 Avantages du D√©coupage

| Aspect | Avant | Apr√®s |
|--------|-------|-------|
| **Testabilit√©** | Difficile (handlers natifs) | Facile (mocking interface) |
| **Extensibilit√©** | Modifications dispers√©es | Ajout de providers |
| **Maintenabilit√©** | Couplage fort | S√©paration claire |
| **R√©utilisabilit√©** | Logique √©parpill√©e | Manager r√©utilisable |

### 7.3 Migration Progressive

#### Phase 1: Extraction Interface (semaine 1)
```typescript
// 1. Cr√©er interfaces
// 2. Wrapper code existant
// 3. Tests de non-r√©gression
```

#### Phase 2: Manager Initial (semaine 2)
```typescript
// 1. Cr√©er CondensationManager
// 2. Migrer getEffectiveConfig
// 3. Migrer shouldCondense
```

#### Phase 3: Provider S√©par√© (semaine 3)
```typescript
// 1. Cr√©er NativeCondensationProvider
// 2. Migrer logique technique
// 3. Brancher Manager ‚Üí Provider
```

#### Phase 4: Refactoring Task (semaine 4)
```typescript
// 1. Remplacer appels directs par Manager
// 2. Nettoyer code legacy
// 3. Documentation finale
```

---

## 8. Cas d'Usage Concrets

### 8.1 Profil Global Simple

```typescript
// Configuration utilisateur standard
const config = {
    autoCondenseContext: true,
    autoCondenseContextPercent: 75,  // 75% du contexte
    profileThresholds: {},           // Pas de personnalisation
}

// D√©clenchement √† 75% avec mod√®le actuel
// Co√ªt moyen pour Claude Sonnet: ~$0.02-0.04
```

### 8.2 Profil Optimis√© Co√ªt

```typescript
// Configuration pour r√©duire les co√ªts
const config = {
    autoCondenseContext: true,
    autoCondenseContextPercent: 80,  // Plus tol√©rant
    condensingApiConfigId: "gpt-4o-mini-profile",
    profileThresholds: {
        "claude-sonnet": 80,         // Condensation moins fr√©quente
        "gpt-4o-mini": 90,           // Encore moins pour le mini
    },
}

// √âconomie: ~90% sur condensation
// Claude Sonnet: $0.075 ‚Üí GPT-4o-mini: $0.004
```

### 8.3 Profil Prompt Personnalis√©

```typescript
// Configuration avec prompt m√©tier sp√©cifique
const config = {
    autoCondenseContext: true,
    autoCondenseContextPercent: 70,
    customCondensingPrompt: `
R√©sume cette conversation technique en pr√©servant:
1. Les d√©cisions architecturales prises
2. Les probl√®mes techniques r√©solus
3. Les points en suspens
4. Le contexte m√©tier sp√©cifique
    `.trim(),
}

// R√©sum√© plus pertinent pour le contexte m√©tier
```

---

## 9. Points d'Attention

### 9.1 Limitations Actuelles

1. **Pas de retry automatique** si condensation √©choue
2. **Validation limit√©e** du r√©sum√© g√©n√©r√©
3. **Pas de cache** des r√©sum√©s
4. **Pas de m√©triques** sur qualit√© de condensation
5. **Pas de A/B testing** entre prompts

### 9.2 Risques Techniques

| Risque | Impact | Mitigation |
|--------|--------|-----------|
| Handler invalide | Erreur fatale | Validation + fallback |
| Contexte grandit | Boucle infinie | V√©rification stricte |
| Co√ªt explosif | Budget d√©pass√© | Limites + alertes |
| R√©sum√© m√©diocre | Perte de contexte | Validation s√©mantique |
| Latence √©lev√©e | UX d√©grad√©e | Timeout + async |

### 9.3 Opportunit√©s d'Am√©lioration

1. **Cache de r√©sum√©s**: √âviter re-condensation identique
2. **M√©triques qualit√©**: Score de coh√©rence du r√©sum√©
3. **A/B testing**: Comparer prompts/mod√®les
4. **Condensation progressive**: Par chunks vs tout-ou-rien
5. **Pr√©-condensation**: Anticiper d√©clenchement

---

## 10. Conclusion

### 10.1 D√©coupage Recommand√©

| Composant | Responsabilit√© | Justification |
|-----------|---------------|---------------|
| **NativeProvider** | Techniques LLM | Acc√®s direct APIs, streaming, tokens |
| **Manager** | Orchestration m√©tier | Configuration, d√©cisions, strat√©gies |
| **Interfaces** | Contrats | Type-safety, testabilit√©, extensibilit√© |

### 10.2 Prochaines √âtapes

1. ‚úÖ **Valider d√©coupage** avec √©quipe (ce document)
2. üîÑ **Cr√©er interfaces** communes Provider/Manager
3. üìù **Documenter contrats** API d√©taill√©s
4. üß™ **Impl√©menter Provider** s√©par√© + tests
5. üîß **Cr√©er Manager** avec logique m√©tier
6. üîÄ **Migrer Task** vers nouvelle architecture
7. üßπ **Cleanup** code legacy

### 10.3 B√©n√©fices Attendus

- **Maintenabilit√©**: +40% (s√©paration claire)
- **Testabilit√©**: +60% (mocking facile)
- **Extensibilit√©**: +80% (nouveaux providers)
- **Performance**: +10% (optimisations cibl√©es)

---

**Auteur**: Syst√®me d'Analyse Roo Code  
**R√©vision**: v1.0  
**Prochaine R√©vision**: Apr√®s impl√©mentation Phase 1