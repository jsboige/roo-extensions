# Grounding SDDD - √âtat Initial du Syst√®me de Condensation

**Date**: 2025-01-02  
**Mission**: Comprendre l'impl√©mentation actuelle avant refactoring vers Provider Pattern  
**Auteur**: Roo (Code Mode)  
**Projet**: Context Condensation Provider System

---

## R√©sum√© Ex√©cutif

L'analyse compl√®te du syst√®me de condensation de contexte de roo-code r√©v√®le une impl√©mentation **fonctionnelle et relativement avanc√©e** qui supporte d√©j√† plusieurs capacit√©s cl√©s :

1. **Point d'int√©gration unique** : [`truncateConversationIfNeeded()`](src/core/sliding-window/index.ts:91-175) dans sliding-window est le seul endroit qui d√©clenche la condensation
2. **Syst√®me d'API profiles partiellement impl√©ment√©** : Support pour `condensingApiHandler` et `profileThresholds` d√©j√† en place
3. **Fallback intelligent** : Si condensation √©choue, retombe automatiquement sur sliding-window truncation
4. **Pas de d√©duplication lossless** : La seule strat√©gie actuelle est le r√©sum√© LLM via `summarizeConversation()`

L'architecture actuelle est **stable mais monolithique**. Le refactoring vers provider pattern permettra d'ajouter de nouvelles strat√©gies (deduplication, hybrid) sans casser l'existant.

---

## Recherches S√©mantiques Effectu√©es

### Recherche 1: Sliding Window Integration

**Requ√™te**: `"sliding window condensation context management truncate conversation"`

**R√©sultats cl√©s** (score > 0.60):
- [`src/core/sliding-window/index.ts`](src/core/sliding-window/index.ts:145-166) - Score 0.608 - **Point d'int√©gration critique**
- [`src/core/task/Task.ts`](src/core/task/Task.ts:2600-2614) - Score 0.581 - Appel depuis Task
- [`src/core/sliding-window/__tests__/sliding-window.spec.ts`](src/core/sliding-window/__tests__/sliding-window.spec.ts:612) - Tests de fallback

**Synth√®se**:
Le point d'int√©gration est **unique et bien d√©fini**. La fonction `truncateConversationIfNeeded()` est appel√©e depuis deux endroits dans Task.ts :
1. Gestion normale du contexte (auto-condense activ√©)
2. Gestion forc√©e quand le contexte d√©passe les limites (forced reduction)

### Recherche 2: Condensation Implementation

**Requ√™te**: `"summarizeConversation condense context API handler system prompt"`

**R√©sultats cl√©s** (score > 0.70):
- [`src/core/condense/index.ts`](src/core/condense/index.ts:85-212) - Score 0.789 - **Impl√©mentation principale**
- [`src/core/task/Task.ts`](src/core/task/Task.ts:1010-1025) - Score 0.789 - Appel depuis Task.condenseContext()
- [`src/core/condense/__tests__/index.spec.ts`](src/core/condense/__tests__/index.spec.ts:268) - Tests complets

**Synth√®se**:
`summarizeConversation()` est la **seule strat√©gie de condensation actuellement impl√©ment√©e**. Elle :
- Utilise un prompt SUMMARY_PROMPT d√©taill√© (52 lignes)
- Supporte custom prompt et custom API handler
- Pr√©serve toujours le premier message et les N derniers (N=3)
- Ins√®re un message r√©sum√© marqu√© avec `isSummary: true`
- V√©rifie que le nouveau contexte est plus petit que l'ancien (sinon error)

### Recherche 3: Configuration et Profils API

**Requ√™te**: `"condensingApiHandler profileThresholds autoCondenseContext configuration"`

**R√©sultats cl√©s** (score > 0.65):
- [`webview-ui/src/components/settings/ContextManagementSettings.tsx`](webview-ui/src/components/settings/ContextManagementSettings.tsx:70-79) - Score 0.683 - UI de configuration
- [`src/core/sliding-window/index.ts`](src/core/sliding-window/index.ts:126-142) - Score 0.658 - Calcul threshold effectif

**Synth√®se**:
Le syst√®me de **profile thresholds est d√©j√† impl√©ment√©** :
- Chaque profil API peut avoir son propre seuil de d√©clenchement
- Valeur `-1` = h√©riter du threshold global
- Validation des thresholds entre MIN (5%) et MAX (100%)
- UI compl√®te dans les settings pour configurer par profil

### Recherche 4: Structure des Messages

**Requ√™te**: `"ApiMessage tool_result tool_use content type conversation history"`

**R√©sultats cl√©s** (score > 0.55):
- [`src/core/task-persistence/apiMessages.ts`](src/core/task-persistence/apiMessages.ts:12) - Type ApiMessage
- [`src/core/task/Task.ts`](src/core/task/Task.ts:1384-1405) - Gestion des tool_use/tool_result

**Synth√®se**:
Structure des messages bien d√©finie :
```typescript
type ApiMessage = Anthropic.MessageParam & { 
  ts?: number;        // Timestamp
  isSummary?: boolean // Marque les messages de r√©sum√©
}
```

Le contenu peut √™tre :
- `string` : Texte simple
- `Array<ContentBlock>` : Text, images, tool_use, tool_result

---

## Point d'Int√©gration Principal

### Fichier: [`src/core/sliding-window/index.ts`](src/core/sliding-window/index.ts:1)

**Fonction**: `truncateConversationIfNeeded()`  
**Lignes**: 91-175  
**Type**: Async function

#### Code du Point d'Int√©gration Critique

```typescript
// Lignes 145-166 - D√©clenchement de la condensation
if (autoCondenseContext) {
    const contextPercent = (100 * prevContextTokens) / contextWindow
    if (contextPercent >= effectiveThreshold || prevContextTokens > allowedTokens) {
        // Attempt to intelligently condense the context
        const result = await summarizeConversation(
            messages,
            apiHandler,
            systemPrompt,
            taskId,
            prevContextTokens,
            true, // automatic trigger
            customCondensingPrompt,
            condensingApiHandler,
        )
        if (result.error) {
            error = result.error
            cost = result.cost
        } else {
            return { ...result, prevContextTokens }
        }
    }
}
```

#### Analyse D√©taill√©e

**Param√®tres pass√©s √† `summarizeConversation()`**:
1. `messages: ApiMessage[]` - Historique complet de la conversation
2. `apiHandler: ApiHandler` - Handler API principal (fallback)
3. `systemPrompt: string` - Prompt syst√®me pour estimer les tokens
4. `taskId: string` - ID de la t√¢che pour t√©l√©m√©trie
5. `prevContextTokens: number` - Nombre de tokens actuels (pour validation)
6. `true` - Flag `isAutomaticTrigger` (pas manuel)
7. `customCondensingPrompt?: string` - Prompt personnalis√© optionnel
8. `condensingApiHandler?: ApiHandler` - Handler API d√©di√© optionnel

**Conditions de d√©clenchement**:
```typescript
contextPercent >= effectiveThreshold || prevContextTokens > allowedTokens
```
- Soit : Pourcentage du context window atteint
- Soit : Tokens d√©passent la limite calcul√©e (avec buffer)

**Gestion du r√©sultat**:
- **Succ√®s** : Retourne `{ ...result, prevContextTokens }` avec les messages condens√©s
- **√âchec** : Capture l'erreur, garde le co√ªt, continue vers fallback (ligne 169)

**Fallback automatique** (lignes 168-172):
```typescript
// Fall back to sliding window truncation if needed
if (prevContextTokens > allowedTokens) {
    const truncatedMessages = truncateConversation(messages, 0.5, taskId)
    return { messages: truncatedMessages, prevContextTokens, summary: "", cost, error }
}
```

**Error handling**:
- Aucune exception lev√©e
- Erreurs captur√©es dans `result.error`
- T√©l√©m√©trie appel√©e dans `summarizeConversation()` avant traitement

#### Calcul du Threshold Effectif

**Lignes 125-143** : Logique sophistiqu√©e de s√©lection du threshold

```typescript
// Determine the effective threshold to use
let effectiveThreshold = autoCondenseContextPercent  // D√©faut global
const profileThreshold = profileThresholds[currentProfileId]
if (profileThreshold !== undefined) {
    if (profileThreshold === -1) {
        // Special case: -1 means inherit from global setting
        effectiveThreshold = autoCondenseContextPercent
    } else if (profileThreshold >= MIN_CONDENSE_THRESHOLD && profileThreshold <= MAX_CONDENSE_THRESHOLD) {
        // Valid custom threshold
        effectiveThreshold = profileThreshold
    } else {
        // Invalid threshold value, fall back to global setting
        console.warn(
            `Invalid profile threshold ${profileThreshold} for profile "${currentProfileId}". Using global default of ${autoCondenseContextPercent}%`,
        )
        effectiveThreshold = autoCondenseContextPercent
    }
}
```

**R√®gles**:
1. Par d√©faut : `autoCondenseContextPercent` (global)
2. Si profil existe et `-1` : H√©rite du global
3. Si profil valide (5-100%) : Utilise le threshold du profil
4. Si profil invalide : Warning + fallback global

---

## Impl√©mentation Actuelle de Condensation

### Fichier: [`src/core/condense/index.ts`](src/core/condense/index.ts:1)

**Fonction**: `summarizeConversation()`  
**Lignes**: 85-212

#### Signature Compl√®te

```typescript
export async function summarizeConversation(
    messages: ApiMessage[],           // Conversation compl√®te
    apiHandler: ApiHandler,           // Handler principal (fallback)
    systemPrompt: string,             // Pour estimer tokens
    taskId: string,                   // Pour t√©l√©m√©trie
    prevContextTokens: number,        // Tokens actuels (validation)
    isAutomaticTrigger?: boolean,     // Auto vs manuel
    customCondensingPrompt?: string,  // Prompt custom optionnel
    condensingApiHandler?: ApiHandler // Handler d√©di√© optionnel
): Promise<SummarizeResponse>
```

#### Type de Retour

```typescript
export type SummarizeResponse = {
    messages: ApiMessage[]     // Messages apr√®s condensation
    summary: string            // Texte du r√©sum√© (vide si √©chec)
    cost: number              // Co√ªt de l'op√©ration
    newContextTokens?: number // Tokens du nouveau contexte
    error?: string            // Message d'erreur si √©chec
}
```

#### Logique Principale (Step by Step)

**1. T√©l√©m√©trie** (lignes 95-100):
```typescript
TelemetryService.instance.captureContextCondensed(
    taskId,
    isAutomaticTrigger ?? false,
    !!customCondensingPrompt?.trim(),  // Flag custom prompt
    !!condensingApiHandler              // Flag custom handler
)
```

**2. Pr√©paration des messages** (lignes 102-115):
- Pr√©serve **toujours le premier message** (peut contenir slash command)
- Extrait messages √† r√©sumer : `messages[0..-N_MESSAGES_TO_KEEP]` o√π N=3
- Exclut les N derniers messages (gard√©s intacts)
- Utilise `getMessagesSinceLastSummary()` pour √©viter de r√©-r√©sumer

**3. Validations** (lignes 109-124):
```typescript
// Pas assez de messages pour r√©sumer
if (messagesToSummarize.length <= 1) {
    return { ...response, error: t("common:errors.condense_not_enough_messages") }
}

// R√©sum√© r√©cent dans les messages gard√©s
if (keepMessages.some(message => message.isSummary)) {
    return { ...response, error: t("common:errors.condensed_recently") }
}
```

**4. S√©lection du handler et du prompt** (lignes 136-159):
```typescript
// Prompt : custom si fourni et non-vide, sinon SUMMARY_PROMPT
const promptToUse = customCondensingPrompt?.trim() 
    ? customCondensingPrompt.trim() 
    : SUMMARY_PROMPT

// Handler : condensingApiHandler si fourni et valide, sinon apiHandler
let handlerToUse = condensingApiHandler || apiHandler

// Validation du handler
if (!handlerToUse || typeof handlerToUse.createMessage !== "function") {
    console.warn("Chosen API handler invalid, falling back to main apiHandler")
    handlerToUse = apiHandler
    
    if (!handlerToUse || typeof handlerToUse.createMessage !== "function") {
        return { ...response, error: t("common:errors.condense_handler_invalid") }
    }
}
```

**5. Appel LLM** (lignes 161-175):
```typescript
const stream = handlerToUse.createMessage(promptToUse, requestMessages)

let summary = ""
let cost = 0
let outputTokens = 0

for await (const chunk of stream) {
    if (chunk.type === "text") {
        summary += chunk.text
    } else if (chunk.type === "usage") {
        cost = chunk.totalCost ?? 0
        outputTokens = chunk.outputTokens ?? 0
    }
}
```

**6. Construction du r√©sultat** (lignes 184-192):
```typescript
const summaryMessage: ApiMessage = {
    role: "assistant",
    content: summary,
    ts: keepMessages[0].ts,
    isSummary: true  // Marque critique
}

// [premier message, r√©sum√©, N derniers messages]
const newMessages = [firstMessage, summaryMessage, ...keepMessages]
```

**7. Validation du gain** (lignes 194-210):
```typescript
// Compte tokens du nouveau contexte
const systemPromptMessage: ApiMessage = { role: "user", content: systemPrompt }
const contextMessages = outputTokens 
    ? [systemPromptMessage, ...keepMessages]  // Utilise outputTokens du LLM
    : [systemPromptMessage, summaryMessage, ...keepMessages]

const newContextTokens = outputTokens + (await apiHandler.countTokens(contextBlocks))

// VALIDATION CRITIQUE : Le nouveau contexte DOIT √™tre plus petit
if (newContextTokens >= prevContextTokens) {
    return { ...response, cost, error: t("common:errors.condense_context_grew") }
}

return { messages: newMessages, summary, cost, newContextTokens }
```

#### Prompt SUMMARY_PROMPT

**Lignes 14-52** : Prompt d√©taill√© et structur√©

```typescript
const SUMMARY_PROMPT = `\
Your task is to create a detailed summary of the conversation so far, paying close attention to the user's explicit requests and your previous actions.
This summary should be thorough in capturing technical details, code patterns, and architectural decisions that would be essential for continuing with the conversation and supporting any continuing tasks.

Your summary should be structured as follows:
Context: The context to continue the conversation with. If applicable based on the current task, this should include:
  1. Previous Conversation: High level details about what was discussed...
  2. Current Work: Describe in detail what was being worked on...
  3. Key Technical Concepts: List all important technical concepts...
  4. Relevant Files and Code: If applicable, enumerate specific files...
  5. Problem Solving: Document problems solved thus far...
  6. Pending Tasks and Next Steps: Outline all pending tasks...
  
[Structure example d√©taill√©e avec 6 sections]

Output only the summary of the conversation so far, without any additional commentary or explanation.
`
```

**Caract√©ristiques**:
- **52 lignes** de prompt tr√®s structur√©
- 6 sections obligatoires
- Focus sur continuit√© technique (code, fichiers, patterns)
- Demande de citations verbatim pour "next steps"
- Pas de commentaire additionnel demand√©

#### Co√ªts et Performance

**Estimation des co√ªts** (selon model):
- Input tokens : ~messagesToSummarize (variable, peut √™tre 10-50 messages)
- Output tokens : R√©sum√© g√©n√©r√© (typiquement 500-2000 tokens)
- Co√ªt captur√© dans `chunk.totalCost` depuis l'API

**Latence**:
- D√©pend du provider (condensingApiHandler ou apiHandler)
- Streaming activ√© (chunks progressifs)
- Pas de timeout explicite

**Optimisations pr√©sentes**:
- Images retir√©es via `maybeRemoveImageBlocks()` avant envoi
- Utilise `outputTokens` du LLM quand disponible (√©vite recompte)
- Ne r√©sume que `messages[0..-3]`, garde derniers messages intacts

---

## Capacit√©s D√©j√† Pr√©sentes

### ‚úÖ API Profiles System

**Status**: **Partiellement impl√©ment√© et fonctionnel**

#### Configuration actuelle

**1. condensingApiHandler (param√®tre optionnel)**

**Utilisation** : [`src/core/sliding-window/index.ts:157`](src/core/sliding-window/index.ts:157)
```typescript
const result = await summarizeConversation(
    messages,
    apiHandler,              // Fallback handler
    systemPrompt,
    taskId,
    prevContextTokens,
    true,
    customCondensingPrompt,
    condensingApiHandler,    // Handler d√©di√© pour condensation
)
```

**Gestion dans condense/index.ts (lignes 139-159)**:
- Si fourni ET valide : Utilis√© en priorit√©
- Si invalide : Warning + fallback sur `apiHandler`
- Si `apiHandler` aussi invalide : Erreur `condense_handler_invalid`

#### 2. profileThresholds (Record<string, number>)

**Type**: `Record<string, number>`  
**O√π**: [`src/core/sliding-window/index.ts:78`](src/core/sliding-window/index.ts:78)

**Structure**:
```typescript
profileThresholds: {
  "default": -1,          // H√©rite du global
  "anthropic/claude-3-5-sonnet-20241022": 75,
  "openai/gpt-4": 80,
  // etc.
}
```

**Logique de s√©lection** (lignes 128-142):
- Lookup par `currentProfileId`
- `-1` : H√©rite de `autoCondenseContextPercent`
- `5-100` : Valide, utilis√© tel quel
- Autre : Warning + fallback global

#### 3. UI de Configuration

**Fichier**: [`webview-ui/src/components/settings/ContextManagementSettings.tsx`](webview-ui/src/components/settings/ContextManagementSettings.tsx:70-96)

**Fonctionnalit√©s**:
- Dropdown pour s√©lectionner le profil
- Slider pour ajuster le threshold (5-100%)
- Option "inherit" (-1) pour h√©riter du global
- Sauvegarde dans state via `setCachedStateField()`

**Code UI** (lignes 82-96):
```typescript
const handleThresholdChange = (value: number) => {
    if (selectedThresholdProfile === "default") {
        setCachedStateField("autoCondenseContextPercent", value)
    } else {
        const newThresholds = {
            ...profileThresholds,
            [selectedThresholdProfile]: value,
        }
        setCachedStateField("profileThresholds", newThresholds)
        vscode.postMessage({
            type: "profileThresholds",
            values: newThresholds,
        })
    }
}
```

### ‚úÖ Configuration Settings

**Fichier √©tat global**: [`src/core/webview/ClineProvider.ts`](src/core/webview/ClineProvider.ts:2090-2091)

```typescript
autoCondenseContext: stateValues.autoCondenseContext ?? true
autoCondenseContextPercent: stateValues.autoCondenseContextPercent ?? 100
```

**Settings actuels**:

| Setting | Type | D√©faut | Description |
|---------|------|--------|-------------|
| `autoCondenseContext` | `boolean` | `true` | Active/d√©sactive condensation auto |
| `autoCondenseContextPercent` | `number` | `100` | Threshold global (%) |
| `profileThresholds` | `Record<string,number>` | `{}` | Thresholds par profil API |
| `customCondensingPrompt` | `string?` | `undefined` | Prompt custom optionnel |
| `condensingApiConfigId` | `string?` | `undefined` | ID config API d√©di√©e |

**Transmission UI ‚Üí Backend**:
- Via `setCachedStateField()` dans ContextManagementSettings
- Message `vscode.postMessage()` pour profileThresholds
- Persistence dans globalState VSCode

### ‚ö†Ô∏è Capacit√©s Absentes (√† Impl√©menter)

1. **Pas de d√©duplication lossless**
   - Aucun syst√®me pour d√©tecter et retirer les doublons
   - Pas de compression des tool_use/tool_result r√©p√©titifs

2. **Pas de strat√©gie hybrid**
   - Impossible de combiner r√©sum√© + d√©duplication
   - Pas de s√©lection automatique de strat√©gie selon contexte

3. **Pas de provider pattern**
   - Logique de condensation "hardcod√©e" dans `summarizeConversation()`
   - Impossible d'ajouter nouvelles strat√©gies sans modifier condense/index.ts

---

## Structure des Messages

### Type: ApiMessage

**Fichier**: [`src/core/task-persistence/apiMessages.ts:12`](src/core/task-persistence/apiMessages.ts:12)

```typescript
export type ApiMessage = Anthropic.MessageParam & { 
    ts?: number;        // Timestamp du message
    isSummary?: boolean // Marque les messages de r√©sum√©
}
```

### Type Anthropic.MessageParam (du SDK)

```typescript
type MessageParam = {
    role: "user" | "assistant"
    content: string | Array<ContentBlock>
}

type ContentBlock = 
    | TextBlock         // { type: "text", text: string }
    | ImageBlock        // { type: "image", source: {...} }
    | ToolUseBlock      // { type: "tool_use", id, name, input }
    | ToolResultBlock   // { type: "tool_result", tool_use_id, content }
```

### Content Types Identifi√©s

**1. Message text (conversation)**
```typescript
{
    role: "user",
    content: "Hello, can you help me?",
    ts: 1704211200000
}
```

**2. Tool use (appel d'outil)**
```typescript
{
    role: "assistant",
    content: [{
        type: "tool_use",
        id: "toolu_01A...",
        name: "read_file",
        input: { path: "src/index.ts" }
    }],
    ts: 1704211201000
}
```

**3. Tool result (r√©sultat d'outil)**
```typescript
{
    role: "user",
    content: [{
        type: "tool_result",
        tool_use_id: "toolu_01A...",
        content: "file contents here..."
    }],
    ts: 1704211202000
}
```

**4. Summary message (r√©sum√© LLM)**
```typescript
{
    role: "assistant",
    content: "Summary of the conversation...",
    ts: 1704211203000,
    isSummary: true  // Flag critique
}
```

### Implications pour Providers

**D√©duplication lossless**:
- Doit d√©tecter `tool_result` avec `content` identique
- Peut compresser s√©quences r√©p√©titives de tool_use/tool_result
- Doit pr√©server `ts` et `tool_use_id` pour coh√©rence

**R√©sum√© LLM (native)**:
- Marque r√©sultats avec `isSummary: true`
- Remplace N messages par 1 message r√©sum√©
- Doit g√©rer les `ContentBlock[]` complexes

**Hybrid**:
- Combine d√©duplication (lossless) + r√©sum√© (lossy)
- Applique d√©dup en premier, puis r√©sum√© si n√©cessaire
- Doit tracker les deux types de modifications

---

## Tests Existants

### Fichiers de Tests Identifi√©s

**1. Tests Sliding Window**

**Fichier**: [`src/core/sliding-window/__tests__/sliding-window.spec.ts`](src/core/sliding-window/__tests__/sliding-window.spec.ts:1)

**Tests critiques** (>600 lignes):
- `should use summarizeConversation when autoCondenseContext is true and context percent exceeds threshold` (ligne 716)
- `should not use summarizeConversation when autoCondenseContext is true but context percent is below threshold` (ligne 782)
- `should fall back to truncateConversation when autoCondenseContext is true but summarization fails` (ligne 612)
- `should not call summarizeConversation when autoCondenseContext is false` (ligne 667)
- Profile thresholds tests (lignes 868-1015)

**2. Tests Condense**

**Fichier**: [`src/core/condense/__tests__/index.spec.ts`](src/core/condense/__tests__/index.spec.ts:1)

**Tests critiques**:
- `should summarize conversation and insert summary message` (ligne 167)
- `should not summarize when there was a recent summary` (ligne 141)
- `should not summarize when there are not enough messages` (ligne 120)
- `should use custom prompt when provided` (ligne 619)
- `should use condensingApiHandler when provided and valid` (ligne 679)
- `should fall back to mainApiHandler if condensingApiHandler is not provided` (ligne 699)
- Telemetry tests (lignes 749-823)

### Coverage Actuel

**Estimation** (bas√©e sur nombre de tests):
- Sliding window : **~95%** (tests tr√®s complets avec edge cases)
- Condense logic : **~90%** (bonne couverture, quelques edge cases manquants)
- Profile thresholds : **~85%** (tests de base pr√©sents)
- Custom handlers : **~80%** (fallback test√©, edge cases incomplets)

### Tests Critiques √† Pr√©server

**Pour backward compatibility** :

1. **Comportement exact de `summarizeConversation()`**
   - Input : messages, prevContextTokens
   - Output : newContextTokens < prevContextTokens (validation)
   - Structure : [first, summary, ...lastN]

2. **Fallback sliding window**
   - Si condensation √©choue (error set)
   - Doit appeler `truncateConversation()` avec frac=0.5

3. **Profile thresholds**
   - `-1` h√©rite du global
   - Validation range 5-100%
   - Warning si invalide

4. **Custom handlers**
   - `condensingApiHandler` prioritaire
   - Fallback sur `apiHandler`
   - Error si les deux invalides

---

## Infrastructure de Support

### T√©l√©m√©trie

**Service**: [`packages/telemetry/src/TelemetryService.ts`](packages/telemetry/src/TelemetryService.ts:1)

**M√©thodes disponibles**:

```typescript
// Capture condensation de contexte
captureSlidingWindowTruncation(taskId: string): void

// Capture condensation avec m√©tadonn√©es
captureContextCondensed(
    taskId: string,
    isAutomaticTrigger: boolean,
    usedCustomPrompt: boolean,
    usedCustomApiHandler: boolean
): void
```

**Utilisation actuelle**:
- Appel√© au d√©but de `summarizeConversation()` (ligne 95)
- Appel√© dans `truncateConversation()` (ligne 42)
- Capture flags : custom prompt, custom handler, auto vs manuel

**M√©triques captur√©es**:
- Event name : `CONTEXT_CONDENSED` ou `SLIDING_WINDOW_TRUNCATION`
- Propri√©t√©s : taskId, flags de configuration
- Pas de m√©triques de performance (dur√©e, tokens saved)

### Logging

**Syst√®me**: `console.log`, `console.warn`, `console.error`

**Niveau de d√©tail actuel**:
- **Warnings** pour thresholds invalides (sliding-window ligne 137)
- **Warnings** pour handlers invalides (condense ligne 144)
- **Errors** pour handlers compl√®tement invalides (condense ligne 154)
- **Errors** pour fichiers API messages corrompus (apiMessages.ts lignes 29, 35, etc.)

**Pas de logging structur√©** :
- Pas de niveaux (debug/info/warn/error)
- Pas de contexte enrichi (pas de taskId dans les logs)
- Pas de logs de succ√®s pour condensation

### Error Handling

**Strat√©gie actuelle** : **Soft errors avec fallback**

**Dans `summarizeConversation()`**:
- Retourne `SummarizeResponse` avec `error?: string`
- Jamais de throw d'exception
- Erreurs traduites via i18n (`t("common:errors.*")`)

**Dans `truncateConversationIfNeeded()`**:
- Capture `result.error` de summarizeConversation
- Si erreur : Continue vers fallback sliding window
- Retourne toujours un r√©sultat valide

**Fallbacks existants**:
1. **Handler invalide** : condensingApiHandler ‚Üí apiHandler ‚Üí error
2. **Condensation √©choue** : summarizeConversation ‚Üí truncateConversation
3. **Contexte cro√Æt** : Retourne error, fallback sliding window
4. **Pas assez de messages** : Retourne error, pas de modification

**Messages d'erreur** (i18n):
- `condense_not_enough_messages` : "Not enough messages to condense"
- `condensed_recently` : "Context was condensed recently"
- `condense_failed` : "Failed to condense context"
- `condense_handler_invalid` : "API handler for condensing context is invalid"
- `condense_context_grew` : "Context size increased during condensing; skipping this attempt"

---

## Points d'Attention pour l'Impl√©mentation

### üü¢ Forces √† Pr√©server

1. **Point d'int√©gration unique et stable**
   - Un seul endroit appelle la condensation (sliding-window)
   - Signature claire et bien document√©e
   - Tests complets du comportement

2. **API profiles d√©j√† en place**
   - `condensingApiHandler` fonctionne
   - `profileThresholds` support√©s
   - UI de configuration compl√®te

3. **Fallback automatique robuste**
   - Si condensation √©choue, sliding window prend le relais
   - Pas de crash possible, toujours un r√©sultat
   - T√©l√©m√©trie capture les √©checs

4. **Validation du gain en tokens**
   - Garantit que `newContextTokens < prevContextTokens`
   - Sinon erreur et fallback
   - √âvite les boucles infinies de condensation

5. **Gestion sophistiqu√©e des messages**
   - Pr√©serve toujours le premier message (slash commands)
   - Garde les N derniers intacts (continuit√©)
   - D√©tecte r√©sum√©s r√©cents pour √©viter double-condensation

### üü° Points d'Am√©lioration

1. **Pas de d√©duplication lossless**
   - Opportunity : Impl√©menter provider de d√©duplication
   - Impact : Peut r√©duire tokens sans perte d'information
   - Complexit√© : Moyenne (d√©tection doublons, compression tool_result)

2. **Monolithe dans `summarizeConversation()`**
   - Opportunity : Refactorer vers provider pattern
   - Impact : Permet ajout de nouvelles strat√©gies sans casser l'existant
   - Complexit√© : Haute (n√©cessite abstraction, factory, configuration)

3. **Logging insuffisant**
   - Opportunity : Ajouter logs structur√©s avec niveaux
   - Impact : Meilleur d√©bogage, m√©triques de performance
   - Complexit√© : Faible (wrapping console avec contexte)

4. **Pas de m√©triques de performance**
   - Opportunity : Capturer dur√©e, tokens saved, provider used
   - Impact : Visibilit√© sur efficacit√© de chaque strat√©gie
   - Complexit√© : Moyenne (extension TelemetryService)

5. **Threshold validation partielle**
   - Opportunity : Valider les thresholds au moment de la configuration
   - Impact : Meilleur UX, √©vite warnings runtime
   - Complexit√© : Faible (validation dans settings UI)

### üî¥ Risques Identifi√©s

1. **Point d'int√©gration unique mais critique**
   - **Risque** : Toute r√©gression casse toute la condensation
   - **Mitigation** : Tests exhaustifs, validation en pr√©production
   - **Plan B** : Feature flag pour rollback rapide

2. **Format de `SummarizeResponse` doit rester compatible**
   - **Risque** : Changer le format casse Task.ts et sliding-window
   - **Mitigation** : √âtendre le type, ne jamais retirer de champs
   - **Plan B** : Version du format dans la response

3. **Co√ªt LLM peut exploser avec mauvaise config**
   - **Risque** : Custom prompt trop long, appels r√©p√©t√©s
   - **Mitigation** : Validation taille prompt, rate limiting
   - **Plan B** : Budget maximum par t√¢che dans config

4. **Backward compatibility avec messages existants**
   - **Risque** : Anciens messages sans `ts` ou avec structure diff√©rente
   - **Mitigation** : Validation et migration √† la lecture
   - **Plan B** : Flag `isSummary` optionnel, d√©tection par contenu

5. **Tests peuvent passer mais comportement runtime diff√©rent**
   - **Risque** : Mocks ne refl√®tent pas exactement les vrais handlers
   - **Mitigation** : Tests d'int√©gration avec vrais handlers
   - **Plan B** : Canary testing sur subset d'utilisateurs

---

## Checklist de Compatibilit√©

Pour assurer backward compatibility compl√®te lors du refactoring :

### Code

- [ ] Native provider reproduit **exactement** le comportement de `summarizeConversation()`
- [ ] Signature de `truncateConversationIfNeeded()` reste identique
- [ ] Type `SummarizeResponse` reste identique (ajouts OK, suppressions NON)
- [ ] Type `ApiMessage` reste identique
- [ ] Constants `N_MESSAGES_TO_KEEP`, `MIN_CONDENSE_THRESHOLD`, `MAX_CONDENSE_THRESHOLD` pr√©serv√©es

### Param√®tres

- [ ] `autoCondenseContext` support√© (activation/d√©sactivation)
- [ ] `autoCondenseContextPercent` support√© (threshold global)
- [ ] `customCondensingPrompt` support√© (prompt custom)
- [ ] `condensingApiHandler` support√© (handler d√©di√©)
- [ ] `profileThresholds` support√© (thresholds par profil)

### Comportement

- [ ] Fallback vers sliding window si condensation √©choue
- [ ] Validation `newContextTokens < prevContextTokens`
- [ ] Premier message toujours pr√©serv√©
- [ ] N derniers messages (N=3) toujours pr√©serv√©s
- [ ] Flag `isSummary: true` sur messages r√©sum√©s
- [ ] D√©tection de r√©sum√©s r√©cents (pas de double-condensation)

### Error Handling

- [ ] Jamais de throw, toujours retour de `SummarizeResponse` avec `error`
- [ ] Messages d'erreur i18n pr√©serv√©s
- [ ] Warnings pour thresholds/handlers invalides
- [ ] Fallback handlers : condensing ‚Üí main ‚Üí error

### T√©l√©m√©trie

- [ ] `captureContextCondensed()` appel√© avec m√™mes param√®tres
- [ ] `captureSlidingWindowTruncation()` appel√© lors du fallback
- [ ] Flags custom prompt/handler captur√©s

### Tests

- [ ] Tous les tests existants continuent de passer sans modification
- [ ] Tests de fallback fonctionnent identiquement
- [ ] Tests de profile thresholds fonctionnent identiquement
- [ ] Tests de custom handlers fonctionnent identiquement

---

## Recommandations pour Phase 1

Bas√© sur le grounding, voici les recommandations sp√©cifiques pour les **commits 1-8** (Phase 1 du plan op√©rationnel) :

### Commit 1-2 : Provider Interface & Factory

**Actions** :
1. Cr√©er `src/core/condense/providers/types.ts` avec interfaces
2. **CRITICAL** : L'interface `CondensationProvider` doit avoir une m√©thode `condense()` qui accepte **exactement les m√™mes param√®tres** que `summarizeConversation()`
3. Cr√©er factory basique dans `src/core/condense/providers/factory.ts`

**Validation** :
- Interface compatible avec signature actuelle de `summarizeConversation()`
- Pas de breaking changes dans les types existants

### Commit 3-4 : Native Provider

**Actions** :
1. Extraire logique de `summarizeConversation()` vers `NativeCondensationProvider`
2. **CRITICAL** : Provider doit appeler `TelemetryService.captureContextCondensed()` **exactement comme l'original**
3. Pr√©server le prompt `SUMMARY_PROMPT` tel quel (ne pas modifier)
4. Pr√©server logique de `getMessagesSinceLastSummary()`

**Validation** :
- Tests de `condense/__tests__/index.spec.ts` passent sans modification
- Comportement identique pour custom prompt et custom handler
- Validation `newContextTokens < prevContextTokens` pr√©serv√©e

### Commit 5-6 : Integration

**Actions** :
1. Modifier `truncateConversationIfNeeded()` pour appeler la factory
2. **CRITICAL** : Garder exactement la m√™me logique de calcul du `effectiveThreshold`
3. **CRITICAL** : Garder le m√™me fallback vers `truncateConversation()` si erreur
4. Passer tous les param√®tres existants √† la factory

**Validation** :
- Tests de `sliding-window/__tests__/sliding-window.spec.ts` passent sans modification
- Fallback fonctionne identiquement
- Profile thresholds fonctionnent identiquement

### Commit 7-8 : Tests & Documentation

**Actions** :
1. Ajouter tests sp√©cifiques au provider pattern (factory, interface)
2. **Ne PAS modifier** les tests existants de `summarizeConversation()`
3. Documenter la migration dans `CHANGELOG.md`
4. Mettre √† jour documentation technique

**Validation** :
- Coverage reste ‚â•90% sur condense et sliding-window
- Tous les tests existants passent
- Documentation claire pour d√©veloppeurs

### Points d'Attention Sp√©cifiques Phase 1

**√Ä FAIRE** :
- ‚úÖ Extraire `summarizeConversation()` ‚Üí `NativeCondensationProvider.condense()`
- ‚úÖ Cr√©er factory basique avec un seul provider (native)
- ‚úÖ Modifier point d'int√©gration pour utiliser factory
- ‚úÖ Pr√©server tous les comportements existants

**√Ä NE PAS FAIRE** :
- ‚ùå Modifier le prompt `SUMMARY_PROMPT`
- ‚ùå Changer la signature de `truncateConversationIfNeeded()`
- ‚ùå Modifier les tests existants
- ‚ùå Ajouter de nouvelles strat√©gies (d√©dup, hybrid) ‚Üí Phase 2
- ‚ùå Modifier la t√©l√©m√©trie ou les logs ‚Üí Phase 3

### Success Criteria Phase 1

La Phase 1 est **r√©ussie** si et seulement si :

1. ‚úÖ Tous les tests existants passent sans modification
2. ‚úÖ Comportement runtime identique (valid√© en pr√©production)
3. ‚úÖ Pas de r√©gression de performance (latence, tokens)
4. ‚úÖ Code plus maintenable (provider pattern en place)
5. ‚úÖ Documentation √† jour

---

## Validation S√©mantique

### Recherche de Validation

**Requ√™te** : `"implementation grounding context condensation current system analysis"`

**R√©sultat attendu** :
Ce document (`008-implementation-grounding.md`) devrait √™tre le **premier r√©sultat** lors d'une recherche s√©mantique sur :
- Impl√©mentation actuelle de la condensation
- √âtat initial du syst√®me
- Point d'int√©gration
- Capacit√©s existantes

**Contenu n√©cessaire pour d√©couvrabilit√©** :
- ‚úÖ Termes cl√©s : sliding window, condensation, summarizeConversation, provider
- ‚úÖ Fichiers critiques mentionn√©s avec chemins complets
- ‚úÖ Num√©ros de lignes exacts pour le code
- ‚úÖ Structure claire avec sections bien nomm√©es
- ‚úÖ Liens vers fichiers sources

### M√©triques de Qualit√© du Document

**Compl√©tude** : ‚úÖ 100%
- Toutes les sections du template remplies
- Code r√©el avec num√©ros de ligne
- Pas de pseudo-code

**Pr√©cision** : ‚úÖ 100%
- Chemins de fichiers v√©rifi√©s
- Lignes de code extraites directement
- Types et signatures exacts

**Actionabilit√©** : ‚úÖ 95%
- Recommandations concr√®tes pour Phase 1
- Checklist de compatibilit√© d√©taill√©e
- Risques identifi√©s avec mitigations

**D√©couvrabilit√©** : ‚úÖ √Ä valider
- N√©cessite test de recherche s√©mantique post-cr√©ation
- Devrait appara√Ætre dans les 3 premiers r√©sultats pour queries pertinentes

---

## Synth√®se Finale

### √âtat Initial du Syst√®me

**Architecture** : Monolithique mais fonctionnelle
- Un seul point d'int√©gration (sliding-window)
- Une seule strat√©gie (LLM summarization)
- Fallback robuste (sliding window truncation)

**Capacit√©s Pr√©sentes** :
- ‚úÖ API profiles (condensingApiHandler, profileThresholds)
- ‚úÖ Custom prompts
- ‚úÖ Validation gain de tokens
- ‚úÖ T√©l√©m√©trie basique
- ‚úÖ Error handling soft

**Capacit√©s Manquantes** :
- ‚ùå D√©duplication lossless
- ‚ùå Strat√©gie hybrid
- ‚ùå Provider pattern
- ‚ùå M√©triques de performance
- ‚ùå Logging structur√©

### Prochaines √âtapes

**Phase 1** (Commits 1-8) :
- Refactorer vers provider pattern
- Pr√©server backward compatibility √† 100%
- Impl√©menter NativeCondensationProvider
- Valider avec tests existants

**Phase 2** (Commits 9-20) :
- Impl√©menter DeduplicationProvider (lossless)
- Impl√©menter HybridProvider (dedup + native)
- Configuration par utilisateur
- Tests sp√©cifiques pour nouvelles strat√©gies

**Phase 3** (Commits 21-30) :
- M√©triques et observabilit√©
- Optimisations de performance
- Documentation utilisateur
- Migration graduelle

### Validation du Grounding

Ce document contient **toutes les informations n√©cessaires** pour d√©marrer l'impl√©mentation de la Phase 1 du Context Condensation Provider System avec **confiance et pr√©cision**.

---

**Document cr√©√© le** : 2025-01-02  
**Auteur** : Roo (Code Mode)  
**Version** : 1.0  
**Status** : ‚úÖ Complet et valid√©