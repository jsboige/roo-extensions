# Analyse du M√©canisme de Condensation de Contexte - Roo-Code

**Date :** 8 janvier 2025  
**Objectif :** Cartographier et documenter le m√©canisme de condensation de contexte de roo-code  
**M√©thodologie :** Semantic Documentation Driven Design (SDDD)

## üéØ R√©sum√© Ex√©cutif

Cette analyse d√©taille le m√©canisme de condensation de contexte de roo-code, une fonctionnalit√© critique qui g√®re automatiquement la taille des conversations pour respecter les limites de tokens des mod√®les LLM. Le syst√®me impl√©mente une approche hybride combinant :

1. **Condensation intelligente** via LLM (prioritaire)
2. **Troncature par fen√™tre glissante** (fallback)

## üìã Plan d'Analyse

### Phase 1 - Grounding S√©mantique ‚úÖ
- [x] Recherche s√©mantique triangul√©e : "context condensation", "token limit management", "sliding window implementation"
- [x] Identification des fichiers cl√©s : [`src/core/sliding-window/index.ts`](../roo-code/src/core/sliding-window/index.ts), [`src/core/condense/index.ts`](../roo-code/src/core/condense/index.ts)
- [x] Immersion dans le code source

### Phase 2 - Analyse Technique üîÑ
- [ ] Cartographier le flux de condensation
- [ ] Identifier les composants cl√©s
- [ ] Identifier les points d'interception potentiels

### Phase 3 - Validation üîÑ
- [ ] Validation s√©mantique du document
- [ ] Test de d√©couvrabilit√©

### Phase 4 - Rapport de Mission üîÑ
- [ ] Rapport d'activit√© complet
- [ ] Synth√®se pour grounding orchestrateur

## üîç D√©couvertes Initiales

### Fichiers Cl√©s Identifi√©s

1. **[`src/core/sliding-window/index.ts`](../roo-code/src/core/sliding-window/index.ts)** - Module principal de gestion de la fen√™tre glissante
2. **[`src/core/condense/index.ts`](../roo-code/src/core/condense/index.ts)** - Module de condensation intelligente via LLM
3. **[`src/core/task/Task.ts`](../roo-code/src/core/task/Task.ts)** - Point d'int√©gration dans les t√¢ches
4. **Interface utilisateur** - Composants React pour l'affichage des condensations

### Architecture G√©n√©rale

Le syst√®me fonctionne selon une logique de **priorit√© cascad√©e** :

```
D√©clenchement ‚Üí Condensation LLM ‚Üí Fallback Troncature ‚Üí Pas d'action
     ‚Üì               ‚Üì                    ‚Üì              ‚Üì
   Seuil atteint   Succ√®s ?           √âchec LLM      Contexte OK
```

## üìä Analyse Technique D√©taill√©e

### 1. Point d'Entr√©e Principal

**Fonction :** [`truncateConversationIfNeeded()`](../roo-code/src/core/sliding-window/index.ts:91)

**Responsabilit√© :** Orchestrateur principal qui d√©cide si une action est n√©cessaire

**Param√®tres cl√©s :**
- `messages: ApiMessage[]` - Historique de conversation
- `totalTokens: number` - Tokens actuels (sans dernier message)
- `contextWindow: number` - Taille de fen√™tre du mod√®le
- `autoCondenseContext: boolean` - Active/d√©sactive la condensation LLM
- `autoCondenseContextPercent: number` - Seuil de d√©clenchement global
- `profileThresholds: Record<string, number>` - Seuils par profil

### 2. Logique de D√©clenchement

**Calcul des tokens effectifs :**
```typescript
const prevContextTokens = totalTokens + lastMessageTokens
const allowedTokens = contextWindow * (1 - TOKEN_BUFFER_PERCENTAGE) - reservedTokens
```

**Constantes importantes :**
- `TOKEN_BUFFER_PERCENTAGE = 0.1` (10% de buffer)
- `ANTHROPIC_DEFAULT_MAX_TOKENS` - Tokens r√©serv√©s pour la r√©ponse

**Conditions de d√©clenchement :**
1. `contextPercent >= effectiveThreshold` OU
2. `prevContextTokens > allowedTokens`

### 3. Gestion des Seuils par Profil

Le syst√®me supporte des seuils personnalis√©s par profil :

```typescript
let effectiveThreshold = autoCondenseContextPercent
const profileThreshold = profileThresholds[currentProfileId]

if (profileThreshold !== undefined) {
    if (profileThreshold === -1) {
        // H√©rite du param√®tre global
        effectiveThreshold = autoCondenseContextPercent
    } else if (profileThreshold >= MIN_CONDENSE_THRESHOLD && profileThreshold <= MAX_CONDENSE_THRESHOLD) {
        // Seuil personnalis√© valide
        effectiveThreshold = profileThreshold
    }
}
```

### 4. Condensation Intelligente (Prioritaire)

**Fonction :** [`summarizeConversation()`](../roo-code/src/core/condense/index.ts:85)

**M√©canisme :**
1. Garde les `N_MESSAGES_TO_KEEP = 3` derniers messages
2. R√©sume les messages pr√©c√©dents via LLM
3. Remplace l'historique par un message de r√©sum√©

**Prompt de r√©sum√© :** Structure d√©taill√©e en 6 sections :
1. Previous Conversation
2. Current Work  
3. Key Technical Concepts
4. Relevant Files and Code
5. Problem Solving
6. Pending Tasks and Next Steps

**Validation de qualit√© :**
- V√©rifie que le r√©sum√© n'est pas vide
- S'assure que le nouveau contexte est plus petit : `newContextTokens < prevContextTokens`

### 5. Troncature par Fen√™tre Glissante (Fallback)

**Fonction :** [`truncateConversation()`](../roo-code/src/core/sliding-window/index.ts:41)

**M√©canisme :**
- Garde toujours le premier message (syst√®me)
- Supprime 50% des messages interm√©diaires (`fracToRemove = 0.5`)
- Arrondit √† un nombre pair de messages supprim√©s
- Garde les messages r√©cents

**T√©l√©m√©trie :** Capture l'√©v√©nement `SLIDING_WINDOW_TRUNCATION`

## üîß Points d'Interception Identifi√©s

### Points de Personnalisation Potentiels

1. **Seuils de d√©clenchement**
   - Modification de `TOKEN_BUFFER_PERCENTAGE`
   - Personnalisation des seuils par profil
   - Ajout de conditions de d√©clenchement personnalis√©es

2. **Strat√©gie de condensation**
   - Remplacement du prompt de r√©sum√© (`SUMMARY_PROMPT`)
   - Utilisation d'un `customCondensingPrompt`
   - Utilisation d'un `condensingApiHandler` diff√©rent

3. **Strat√©gie de troncature**
   - Modification de `fracToRemove` (actuellement 0.5)
   - Changement de `N_MESSAGES_TO_KEEP` (actuellement 3)
   - Logique de s√©lection des messages √† conserver

4. **Validation et contr√¥le qualit√©**
   - Ajout de m√©triques de qualit√© du r√©sum√©
   - Validation s√©mantique du contenu condens√©
   - M√©canismes de rollback en cas d'√©chec

### Architecture d'Extension

Le syst√®me est con√ßu avec des points d'injection clairs :

```typescript
// Point d'injection pour strat√©gies personnalis√©es
interface CondensationStrategy {
    shouldCondense(context: CondensationContext): boolean
    condense(messages: ApiMessage[]): Promise<SummarizeResponse>
}

// Point d'injection pour validation personnalis√©e  
interface CondensationValidator {
    validate(original: ApiMessage[], condensed: ApiMessage[]): ValidationResult
}
```

## üéØ Prochaines √âtapes

1. **Cartographie compl√®te du flux** - Diagrammes Mermaid
2. **Identification des d√©pendances** - Modules connexes
3. **Points d'interception d√©taill√©s** - Interfaces et hooks
4. **Validation s√©mantique** - Test de d√©couvrabilit√©

## üó∫Ô∏è Cartographie du Flux de Condensation

### Flux Principal - Vue d'Ensemble

```mermaid
flowchart TD
    A[Nouvelle requ√™te utilisateur] --> B[truncateConversationIfNeeded()]
    B --> C{Calcul tokens effectifs}
    C --> D[prevContextTokens = totalTokens + lastMessageTokens]
    D --> E[allowedTokens = contextWindow * 0.9 - reservedTokens]
    E --> F{Seuil atteint ?}
    
    F -->|Non| Z[Pas d'action - Retour messages originaux]
    F -->|Oui| G{autoCondenseContext activ√© ?}
    
    G -->|Non| P[Troncature directe par fen√™tre glissante]
    G -->|Oui| H[Tentative condensation LLM]
    
    H --> I{Condensation r√©ussie ?}
    I -->|Oui| J[Retour messages condens√©s]
    I -->|Non| K{Tokens > allowedTokens ?}
    
    K -->|Non| L[Retour messages originaux avec erreur]
    K -->|Oui| P
    
    P --> M[truncateConversation - Suppression 50% messages]
    M --> N[T√©l√©m√©trie SLIDING_WINDOW_TRUNCATION]
    N --> O[Retour messages tronqu√©s]
    
    style H fill:#e1f5fe
    style P fill:#fff3e0
    style J fill:#e8f5e8
    style O fill:#fff3e0
```

### Flux de Condensation LLM - D√©tail

```mermaid
flowchart TD
    A[summarizeConversation()] --> B[T√©l√©m√©trie captureContextCondensed]
    B --> C[getMessagesSinceLastSummary()]
    C --> D{Messages √† r√©sumer > 1 ?}
    
    D -->|Non| E[Erreur: Pas assez de messages]
    D -->|Oui| F[Garde les N_MESSAGES_TO_KEEP derniers]
    
    F --> G{R√©sum√© r√©cent existe ?}
    G -->|Oui| H[Erreur: Condens√© r√©cemment]
    G -->|Non| I[Pr√©paration requ√™te LLM]
    
    I --> J[S√©lection API Handler]
    J --> K{customCondensingPrompt fourni ?}
    K -->|Oui| L[Utilise prompt personnalis√©]
    K -->|Non| M[Utilise SUMMARY_PROMPT par d√©faut]
    
    L --> N[Appel LLM via createMessage()]
    M --> N
    
    N --> O[Streaming de la r√©ponse]
    O --> P{R√©sum√© non vide ?}
    
    P -->|Non| Q[Erreur: Condensation √©chou√©e]
    P -->|Oui| R[Cr√©ation summaryMessage]
    
    R --> S[Calcul newContextTokens]
    S --> T{newContextTokens < prevContextTokens ?}
    
    T -->|Non| U[Erreur: Contexte a grandi]
    T -->|Oui| V[Succ√®s - Retour messages condens√©s]
    
    style N fill:#e1f5fe
    style V fill:#e8f5e8
    style E fill:#ffebee
    style H fill:#ffebee
    style Q fill:#ffebee
    style U fill:#ffebee
```

### Gestion des Seuils par Profil

```mermaid
flowchart TD
    A[D√©termination seuil effectif] --> B[effectiveThreshold = autoCondenseContextPercent]
    B --> C{profileThresholds[currentProfileId] existe ?}
    
    C -->|Non| D[Utilise seuil global]
    C -->|Oui| E{profileThreshold === -1 ?}
    
    E -->|Oui| F[H√©rite du seuil global]
    E -->|Non| G{MIN_CONDENSE_THRESHOLD ‚â§ profileThreshold ‚â§ MAX_CONDENSE_THRESHOLD ?}
    
    G -->|Oui| H[Utilise seuil personnalis√©]
    G -->|Non| I[Warning + Fallback seuil global]
    
    D --> J[effectiveThreshold d√©fini]
    F --> J
    H --> J
    I --> J
    
    J --> K[Comparaison avec contextPercent]
    
    style H fill:#e8f5e8
    style I fill:#fff3e0
```

### Structure des Messages Apr√®s Condensation

```mermaid
graph LR
    A[Messages originaux] --> B[Analyse]
    B --> C[Messages √† r√©sumer]
    B --> D[Messages √† garder - 3 derniers]
    
    C --> E[Appel LLM]
    E --> F[summaryMessage]
    
    F --> G[Nouveau tableau]
    D --> G
    
    G --> H[Messages finaux]
    
    subgraph "Structure finale"
        H --> I[Messages d√©but - 1]
        H --> J[summaryMessage avec isSummary: true]
        H --> K[3 derniers messages originaux]
    end
    
    style F fill:#e1f5fe
    style J fill:#e1f5fe
```

## üîß Composants Cl√©s D√©taill√©s

### 1. Constantes de Configuration

| Constante | Valeur | R√¥le | Point d'interception |
|-----------|--------|------|---------------------|
| `TOKEN_BUFFER_PERCENTAGE` | 0.1 (10%) | Buffer de s√©curit√© | ‚úÖ Modifiable |
| `N_MESSAGES_TO_KEEP` | 3 | Messages r√©cents pr√©serv√©s | ‚úÖ Modifiable |
| `MIN_CONDENSE_THRESHOLD` | 5% | Seuil minimum | ‚úÖ Modifiable |
| `MAX_CONDENSE_THRESHOLD` | 100% | Seuil maximum | ‚úÖ Modifiable |
| `ANTHROPIC_DEFAULT_MAX_TOKENS` | Variable | Tokens r√©serv√©s r√©ponse | ‚ö†Ô∏è D√©pendant du mod√®le |

### 2. Interfaces Cl√©s

```typescript
// Structure de r√©ponse unifi√©e
type TruncateResponse = SummarizeResponse & {
    prevContextTokens: number
}

// Options de troncature
type TruncateOptions = {
    messages: ApiMessage[]
    totalTokens: number
    contextWindow: number
    maxTokens?: number | null
    apiHandler: ApiHandler
    autoCondenseContext: boolean
    autoCondenseContextPercent: number
    systemPrompt: string
    taskId: string
    customCondensingPrompt?: string        // üéØ Point d'injection
    condensingApiHandler?: ApiHandler      // üéØ Point d'injection
    profileThresholds: Record<string, number>  // üéØ Point d'injection
    currentProfileId: string
}

// R√©ponse de condensation
type SummarizeResponse = {
    messages: ApiMessage[]     // Messages apr√®s traitement
    summary: string           // Texte du r√©sum√© (vide si pas de r√©sum√©)
    cost: number             // Co√ªt de l'op√©ration
    newContextTokens?: number // Tokens dans le nouveau contexte
    error?: string           // Message d'erreur si √©chec
}
```

### 3. Points d'Injection Identifi√©s

#### A. Strat√©gies de Condensation Personnalis√©es

```typescript
// Point d'injection dans truncateConversationIfNeeded()
interface CustomCondensationStrategy {
    shouldTrigger(context: CondensationContext): boolean
    condense(messages: ApiMessage[], options: CondensationOptions): Promise<SummarizeResponse>
}

// Utilisation via customCondensingPrompt et condensingApiHandler
const customStrategy = {
    prompt: "Votre prompt personnalis√©...",
    handler: new CustomApiHandler()
}
```

#### B. Validation et Contr√¥le Qualit√©

```typescript
// Point d'injection apr√®s condensation
interface CondensationValidator {
    validate(
        original: ApiMessage[],
        condensed: ApiMessage[],
        summary: string
    ): ValidationResult
}

// Exemple d'impl√©mentation
const qualityValidator = {
    validate: (original, condensed, summary) => {
        // V√©rifications s√©mantiques
        // M√©triques de qualit√©
        // D√©tection de perte d'information critique
        return { isValid: boolean, issues: string[], score: number }
    }
}
```

#### C. M√©triques et T√©l√©m√©trie Personnalis√©es

```typescript
// Extension du syst√®me de t√©l√©m√©trie
interface CustomTelemetryCollector {
    onCondensationStart(context: CondensationContext): void
    onCondensationSuccess(result: CondensationResult): void
    onCondensationFailure(error: CondensationError): void
    onFallbackToTruncation(reason: string): void
}
```

### 4. Hooks et Points d'Extension

#### A. Hooks de Lifecycle

```typescript
// Hook avant condensation
interface PreCondensationHook {
    beforeCondensation(
        messages: ApiMessage[],
        context: CondensationContext
    ): Promise<PreCondensationResult>
}

// Hook apr√®s condensation
interface PostCondensationHook {
    afterCondensation(
        original: ApiMessage[],
        result: SummarizeResponse,
        context: CondensationContext
    ): Promise<PostCondensationResult>
}

// Hook de s√©lection de strat√©gie
interface StrategySelectionHook {
    selectStrategy(context: CondensationContext): CondensationStrategy
}
```

#### B. Architecture de Plugins

```typescript
// Plugin de condensation personnalis√©
interface CondensationPlugin {
    name: string
    priority: number
    
    // D√©termine si le plugin doit s'activer
    shouldActivate(context: CondensationContext): boolean
    
    // Logique de condensation
    condense(messages: ApiMessage[], options: CondensationOptions): Promise<SummarizeResponse>
    
    // Validation des r√©sultats
    validate?(result: SummarizeResponse): ValidationResult
}

// Registry de plugins
class CondensationPluginRegistry {
    private plugins: CondensationPlugin[] = []
    
    register(plugin: CondensationPlugin): void
    unregister(pluginName: string): void
    findBestPlugin(context: CondensationContext): CondensationPlugin | null
}
```

## üéØ Points d'Interception Critiques

### 1. Interception au Niveau des Seuils

**Emplacement :** [`truncateConversationIfNeeded()`](../roo-code/src/core/sliding-window/index.ts:125-142)

```typescript
// AVANT (Code actuel)
let effectiveThreshold = autoCondenseContextPercent
const profileThreshold = profileThresholds[currentProfileId]

// APR√àS (Interception possible)
let effectiveThreshold = await customThresholdResolver.resolve({
    globalThreshold: autoCondenseContextPercent,
    profileThreshold: profileThresholds[currentProfileId],
    context: { messages, totalTokens, contextWindow, taskId }
})
```

**Applications :**
- Seuils adaptatifs bas√©s sur le contenu
- Seuils sp√©cifiques par type de t√¢che
- ML pour optimiser les seuils automatiquement

### 2. Interception du Prompt de Condensation

**Emplacement :** [`summarizeConversation()`](../roo-code/src/core/condense/index.ts:133)

```typescript
// AVANT (Code actuel)
const promptToUse = customCondensingPrompt?.trim() ? customCondensingPrompt.trim() : SUMMARY_PROMPT

// APR√àS (Interception possible)
const promptToUse = await promptGenerator.generatePrompt({
    messages: messagesToSummarize,
    context: { taskType, userPreferences, conversationMetadata },
    fallback: customCondensingPrompt?.trim() || SUMMARY_PROMPT
})
```

**Applications :**
- Prompts adaptatifs selon le domaine
- Prompts multilingues
- Optimisation continue des prompts

### 3. Interception de la Validation Post-Condensation

**Emplacement :** [`summarizeConversation()`](../roo-code/src/core/condense/index.ts:202-205)

```typescript
// AVANT (Code actuel)
if (newContextTokens >= prevContextTokens) {
    const error = t("common:errors.condense_context_grew")
    return { ...response, cost, error }
}

// APR√àS (Interception possible)
const validationResult = await condensationValidator.validate({
    originalMessages: messages,
    condensedMessages: newMessages,
    summary,
    tokenReduction: prevContextTokens - newContextTokens,
    context: { taskId, conversationMetadata }
})

if (!validationResult.isValid) {
    return { ...response, cost, error: validationResult.errorMessage }
}
```

**Applications :**
- Validation s√©mantique de qualit√©
- D√©tection de perte d'information critique
- M√©triques de fid√©lit√© du r√©sum√©

### 4. Interception de la Strat√©gie de Troncature

**Emplacement :** [`truncateConversation()`](../roo-code/src/core/sliding-window/index.ts:41-50)

```typescript
// AVANT (Code actuel)
const rawMessagesToRemove = Math.floor((messages.length - 1) * fracToRemove)
const messagesToRemove = rawMessagesToRemove - (rawMessagesToRemove % 2)

// APR√àS (Interception possible)
const truncationStrategy = await truncationStrategySelector.select({
    messages,
    fracToRemove,
    context: { taskType, conversationFlow, criticalityMap }
})

const messagesToRemove = truncationStrategy.selectMessagesToRemove(messages)
```

**Applications :**
- Troncature intelligente pr√©servant les messages critiques
- Strat√©gies sp√©cifiques par domaine
- Pr√©servation des patterns de conversation importants

## üîÑ Architecture d'Extension Propos√©e

### 1. Interface Unifi√©e de Condensation

```typescript
interface UnifiedCondensationEngine {
    // Configuration
    configure(config: CondensationConfig): void
    
    // Registration de plugins
    registerPlugin(plugin: CondensationPlugin): void
    registerValidator(validator: CondensationValidator): void
    registerHook(hook: CondensationHook): void
    
    // Ex√©cution
    condense(request: CondensationRequest): Promise<CondensationResponse>
    
    // M√©triques et monitoring
    getMetrics(): CondensationMetrics
    getHistory(): CondensationHistory[]
}
```

### 2. Configuration Centralis√©e

```typescript
interface CondensationConfig {
    // Seuils
    thresholds: {
        global: number
        profiles: Record<string, number>
        adaptive: boolean
    }
    
    // Strat√©gies
    strategies: {
        primary: 'llm' | 'truncation' | 'hybrid'
        fallback: 'truncation' | 'error'
        customPrompts: Record<string, string>
    }
    
    // Validation
    validation: {
        enabled: boolean
        rules: ValidationRule[]
        metrics: MetricConfig[]
    }
    
    // Monitoring
    monitoring: {
        telemetry: boolean
        logging: LogLevel
        hooks: HookConfig[]
    }
}
```

### 3. Factory Pattern pour Extensibilit√©

```typescript
class CondensationEngineFactory {
    static create(config: CondensationConfig): UnifiedCondensationEngine {
        const engine = new UnifiedCondensationEngine(config)
        
        // Auto-registration des plugins par d√©faut
        engine.registerPlugin(new LLMCondensationPlugin())
        engine.registerPlugin(new TruncationCondensationPlugin())
        
        // Auto-registration des validators par d√©faut
        engine.registerValidator(new TokenCountValidator())
        engine.registerValidator(new SummaryQualityValidator())
        
        return engine
    }
    
    static createCustom(
        config: CondensationConfig,
        plugins: CondensationPlugin[],
        validators: CondensationValidator[]
    ): UnifiedCondensationEngine {
        const engine = new UnifiedCondensationEngine(config)
        
        plugins.forEach(p => engine.registerPlugin(p))
        validators.forEach(v => engine.registerValidator(v))
        
        return engine
    }
}
```

## üìä Recommandations d'Impl√©mentation

### Phase 1 - Refactoring Sans Impact

1. **Extraction des constantes** vers fichier de configuration
2. **Cr√©ation d'interfaces** pour les points d'injection identifi√©s
3. **Ajout de hooks** non-breaking dans le code existant

### Phase 2 - Extension Progressive

1. **Plugin system** pour strat√©gies personnalis√©es
2. **Configuration centralis√©e** avec backward compatibility
3. **Syst√®me de validation** extensible

### Phase 3 - Optimisation Avanc√©e

1. **ML-driven threshold optimization**
2. **Adaptive prompting** bas√© sur le contexte
3. **Quality metrics** et feedback loop automatique

## üöÄ Conclusion

Le m√©canisme de condensation de contexte de roo-code pr√©sente une architecture robuste avec des **points d'interception clairs** pour la personnalisation. L'approche hybride (LLM + troncature) offre une excellente balance entre qualit√© et fiabilit√©.

**Points cl√©s pour l'extensibilit√© :**
- ‚úÖ **Architecture modulaire** facilement extensible
- ‚úÖ **Points d'injection bien d√©finis** dans le flux
- ‚úÖ **Syst√®me de configuration** d√©j√† partiellement en place
- ‚úÖ **T√©l√©m√©trie int√©gr√©e** pour le monitoring

**Opportunit√©s d'am√©lioration identifi√©es :**
- üéØ Plugin system pour strat√©gies personnalis√©es
- üéØ Validation s√©mantique de qualit√©
- üéØ Seuils adaptatifs bas√©s sur ML
- üéØ M√©triques de fid√©lit√© automatis√©es

---

*Analyse compl√®te - Phases 1 et 2 finalis√©es*